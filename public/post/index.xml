<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 趣味互联网</title>
    <link>http://:1313/tmp/post/</link>
    <description>Recent content in Posts on 趣味互联网</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Jul 2015 06:41:12 +0000</lastBuildDate>
    <atom:link href="http://:1313/tmp/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Golang中空字符表示</title>
      <link>http://:1313/tmp/2015/07/golang%E4%B8%AD%E7%A9%BA%E5%AD%97%E7%AC%A6%E8%A1%A8%E7%A4%BA/</link>
      <pubDate>Wed, 15 Jul 2015 06:41:12 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/07/golang%E4%B8%AD%E7%A9%BA%E5%AD%97%E7%AC%A6%E8%A1%A8%E7%A4%BA/</guid>
      <description>&lt;p&gt;空字符（Null character）又称结束符，缩写NUL，是一个数值为0的控制字符。在C语言中空字符用来表示字符串的结束。&lt;/p&gt;

&lt;p&gt;在C语言中也可以直接插入空字符：&lt;/p&gt;

&lt;div class=&#34;codecolorer-container c blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;c codecolorer&#34;&gt;
          &lt;span class=&#34;co2&#34;&gt;#include &lt;stdio.h&gt;&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;int&lt;/span&gt; main&lt;span class=&#34;br0&#34;&gt;&amp;#40;&lt;/span&gt;&lt;span class=&#34;kw4&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#41;&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;br0&#34;&gt;&amp;#123;&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;a href=&#34;http://www.opengroup.org/onlinepubs/009695399/functions/puts.html&#34;&gt;&lt;span class=&#34;kw3&#34;&gt;puts&lt;/span&gt;&lt;/a&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#40;&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;hello&lt;span class=&#34;es5&#34;&gt;\0&lt;/span&gt;world&#34;&lt;/span&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#41;&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;;&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;br0&#34;&gt;&amp;#125;&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;但是在Go中，类似的代码是不行的：&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;kw1&#34;&gt;package&lt;/span&gt; main&lt;br /&gt; &lt;span class=&#34;kw1&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;st0&#34;&gt;&#34;fmt&#34;&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; main&lt;span class=&#34;sy1&#34;&gt;(){&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; fmt&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Println&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;hello\0world&#34;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;co1&#34;&gt;//print: /tmp/g.go:4: non-octal character in escape sequence: w&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;查看文档：&lt;a href=&#34;https://golang.org/ref/spec#String_literals&#34;&gt;https://golang.org/ref/spec#String_literals&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;修改一下即可：&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;kw1&#34;&gt;package&lt;/span&gt; main&lt;br /&gt; &lt;span class=&#34;kw1&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;st0&#34;&gt;&#34;fmt&#34;&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; main&lt;span class=&#34;sy1&#34;&gt;(){&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; fmt&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Println&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;hello&lt;span class=&#34;es2&#34;&gt;\000&lt;/span&gt;world&#34;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>终于拿到驾照啦</title>
      <link>http://:1313/tmp/2015/07/%E7%BB%88%E4%BA%8E%E6%8B%BF%E5%88%B0%E9%A9%BE%E7%85%A7%E5%95%A6/</link>
      <pubDate>Sat, 11 Jul 2015 11:01:06 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/07/%E7%BB%88%E4%BA%8E%E6%8B%BF%E5%88%B0%E9%A9%BE%E7%85%A7%E5%95%A6/</guid>
      <description>&lt;p&gt;从3月22日到昨天（7月10），历时三个半月终于拿到驾照了 &lt;img src=&#34;http://blog.webfuns.net/wp-includes/images/smilies/simple-smile.png&#34; alt=&#34;:)&#34; class=&#34;wp-smiley&#34; style=&#34;height: 1em; max-height: 1em;&#34; /&gt; 。&lt;/p&gt;

&lt;p&gt;不得不说工作之后再学车，真是一个磨人的事情。之前本来打算上学的时候就把驾照拿下的，因为毕业的事情耽搁啦。这其中也有自己拖延症的原因，有些事情还是早作早完成的好啊。&lt;/p&gt;

&lt;p&gt;学车前就听说驾校的教练各种变态。自己亲身体验之后，真是一肚子泪。有些教练确实相当不负责任，而且态度蛮横恶劣。我这次就遇到了几个，幸亏后来的几个教练都非常好。要不然自己很难顺利的拿到驾照不说，也学不到啥东西。&lt;/p&gt;

&lt;p&gt;整个考试过程还是挺顺利的。就考科目二的时候自己异常紧张，也许是因为自己长时间没有参加过像样的考试了。不过紧张都是考试前，一旦上了考场也就没那么紧张了。最终科目二还考了个满分 &lt;img src=&#34;http://blog.webfuns.net/wp-includes/images/smilies/simple-smile.png&#34; alt=&#34;:)&#34; class=&#34;wp-smiley&#34; style=&#34;height: 1em; max-height: 1em;&#34; /&gt; 。&lt;/p&gt;

&lt;p&gt;开车其实是一件需要非常认真和高度集中精力的事情。无论驾校和教练怎样，自己在学习的时候一定要认真仔细。把该掌握的都掌握，好好练习驾驶技能。教练提醒的地方一定要认真记好，最好能够理解避免死记硬背。&lt;/p&gt;

&lt;p&gt;虽然拿到驾照了，但是其实整个学习的过程都是以拿驾照为目的的，其实驾驶技能只能说是掌握了。从一个门外汉变成了一只菜鸟而已，以后需要学习的东西还多着呢。。。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[转]Inside NGINX: How We Designed for Performance &amp;#038; Scale</title>
      <link>http://:1313/tmp/2015/06/%E8%BD%ACinside-nginx-how-we-designed-for-performance-</link>
      <pubDate>Sat, 13 Jun 2015 15:06:27 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/06/%E8%BD%ACinside-nginx-how-we-designed-for-performance-</guid>
      <description>

&lt;p&gt;NGINX leads the pack in web performance, and it’s all due to the way the software is designed. Whereas many web servers and application servers use a simple threaded or process-based architecture, NGINX stands out with a sophisticated event-driven architecture that enables it to scale to hundreds of thousands of concurrent connections on modern hardware.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;http://nginx.com/resources/library/infographic-inside-nginx/&#34;&gt;Inside NGINX&lt;/a&gt; infographic drills down from the high-level process architecture to illustrate how NGINX handles multiple connections within a single process. This blog explains how it all works in further detail.&lt;/p&gt;

&lt;h2 id=&#34;setting-the-scene-the-nginx-process-model:19032429da545135790f588d1d3e4370&#34;&gt;Setting the Scene – the NGINX Process Model&lt;/h2&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1939&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/06/Screen-Shot-2015-06-08-at-12.36.30-PM.png&#34; alt=&#34;Screen-Shot-2015-06-08-at-12.36.30-PM&#34; width=&#34;740&#34; height=&#34;439&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To better understand this design, you need to understand how NGINX runs. NGINX has a master process (which performs the privileged operations such as reading configuration and binding to ports) and a number of worker and helper processes.&lt;/p&gt;

&lt;div class=&#34;codecolorer-container bash blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;8&lt;br /&gt;9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;bash codecolorer&#34;&gt;
          &lt;span class=&#34;co0&#34;&gt;# service nginx restart&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy0&#34;&gt;*&lt;/span&gt; Restarting nginx&lt;br /&gt; &lt;span class=&#34;co0&#34;&gt;# ps -ef --forest | grep nginx&lt;/span&gt;&lt;br /&gt; root &lt;span class=&#34;nu0&#34;&gt;32475&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;13&lt;/span&gt;:&lt;span class=&#34;nu0&#34;&gt;36&lt;/span&gt; ? 00:00:00 nginx: master process &lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;usr&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;sbin&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;nginx \&lt;br /&gt; &lt;span class=&#34;re5&#34;&gt;-c&lt;/span&gt; &lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;etc&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;nginx&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;nginx.conf&lt;br /&gt; nginx &lt;span class=&#34;nu0&#34;&gt;32476&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;32475&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;13&lt;/span&gt;:&lt;span class=&#34;nu0&#34;&gt;36&lt;/span&gt; ? 00:00:00 \_ nginx: worker process&lt;br /&gt; nginx &lt;span class=&#34;nu0&#34;&gt;32477&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;32475&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;13&lt;/span&gt;:&lt;span class=&#34;nu0&#34;&gt;36&lt;/span&gt; ? 00:00:00 \_ nginx: worker process&lt;br /&gt; nginx &lt;span class=&#34;nu0&#34;&gt;32479&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;32475&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;13&lt;/span&gt;:&lt;span class=&#34;nu0&#34;&gt;36&lt;/span&gt; ? 00:00:00 \_ nginx: worker process&lt;br /&gt; nginx &lt;span class=&#34;nu0&#34;&gt;32480&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;32475&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;13&lt;/span&gt;:&lt;span class=&#34;nu0&#34;&gt;36&lt;/span&gt; ? 00:00:00 \_ nginx: worker process&lt;br /&gt; nginx &lt;span class=&#34;nu0&#34;&gt;32481&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;32475&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;13&lt;/span&gt;:&lt;span class=&#34;nu0&#34;&gt;36&lt;/span&gt; ? 00:00:00 \_ nginx: cache manager process&lt;br /&gt; nginx &lt;span class=&#34;nu0&#34;&gt;32482&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;32475&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;13&lt;/span&gt;:&lt;span class=&#34;nu0&#34;&gt;36&lt;/span&gt; ? 00:00:00 \_ nginx: cache loader process
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;On this 4-core server, the NGINX master process creates 4 worker processes and a couple of cache helper processes which manage the on-disk content cache.&lt;/p&gt;

&lt;h2 id=&#34;why-is-architecture-important:19032429da545135790f588d1d3e4370&#34;&gt;Why Is Architecture Important?&lt;/h2&gt;

&lt;p&gt;The fundamental basis of any Unix application is the thread or process. (From the Linux OS perspective, threads and processes are mostly identical; the major difference is the degree to which they share memory.) A thread or process is a self-contained set of instructions that the operating system can schedule to run on a CPU core. Most complex applications run multiple threads or processes in parallel for two reasons:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;They can use more compute cores at the same time.&lt;/li&gt;
&lt;li&gt;Threads and processes make it very easy to do operations in parallel (for example, to handle multiple connections at the same time).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Processes and threads consume resources. They each use memory and other OS resources, and they need to be swapped on and off the cores (an operation called a &lt;em&gt;context switch&lt;/em&gt;). Most modern servers can handle hundreds of small, active threads or processes simultaneously, but performance degrades seriously once memory is exhausted or when high I/O load causes a large volume of context switches.&lt;/p&gt;

&lt;p&gt;The common way to design network applications is to assign a thread or process to each connection. This architecture is simple and easy to implement, but it does not scale when the application needs to handle thousands of simultaneous connections.&lt;/p&gt;

&lt;h2 id=&#34;how-does-nginx-work:19032429da545135790f588d1d3e4370&#34;&gt;How Does NGINX Work?&lt;/h2&gt;

&lt;p&gt;NGINX uses a predictable process model that is tuned to the available hardware resources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;master&lt;/em&gt; process performs the privileged operations such as reading configuration and binding to ports, and then creates a small number of child processes (the next three types).&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;cache loader&lt;/em&gt; process runs at startup to load the disk-based cache into memory, and then exits. It is scheduled conservatively, so its resource demands are low.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;cache manager&lt;/em&gt; process runs periodically and prunes entries from the disk caches to keep them within the configured sizes.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;worker&lt;/em&gt; processes do all of the work! They handle network connections, read and write content to disk, and communicate with upstream servers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The NGINX configuration recommended in most cases – running one worker process per CPU core – makes the most efficient use of hardware resources. You configure it by including the &lt;a href=&#34;http://nginx.org/en/docs/ngx_core_module.html#worker_processes&#34; target=&#34;_blank&#34;&gt;worker_processes auto&lt;/a&gt; directive in the configuration:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;worker_processes auto;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When an NGINX server is active, only the worker processes are busy. Each worker process handles multiple connections in a non-blocking fashion, reducing the number of context switches.&lt;/p&gt;

&lt;p&gt;Each worker process is single-threaded and runs independently, grabbing new connections and processing them. The processes can communicate using shared memory for shared cache data, session persistence data, and other shared resources.&lt;/p&gt;

&lt;h2 id=&#34;inside-the-nginx-worker-process:19032429da545135790f588d1d3e4370&#34;&gt;Inside the NGINX Worker Process&lt;/h2&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1940&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/06/Screen-Shot-2015-06-08-at-12.39.48-PM.png&#34; alt=&#34;Screen-Shot-2015-06-08-at-12.39.48-PM&#34; width=&#34;866&#34; height=&#34;405&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Each NGINX worker process is initialized with the NGINX configuration and is provided with a set of listen sockets by the master process.&lt;/p&gt;

&lt;p&gt;The NGINX worker processes begin by waiting for events on the listen sockets (&lt;a href=&#34;http://nginx.org/en/docs/ngx_core_module.html#accept_mutex&#34; target=&#34;_blank&#34;&gt;accept_mutex&lt;/a&gt; and &lt;a href=&#34;http://nginx.com/blog/socket-sharding-nginx-release-1-9-1/&#34; target=&#34;_blank&#34;&gt;kernel socket sharding&lt;/a&gt;). Events are initiated by new incoming connections. These connections are assigned to a *state machine* – the HTTP state machine is the most commonly used, but NGINX also implements state machines for stream (raw TCP) traffic and for a number of mail protocols (SMTP, IMAP, and POP3).&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1941&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/06/Screen-Shot-2015-06-08-at-12.40.32-PM.png&#34; alt=&#34;Screen-Shot-2015-06-08-at-12.40.32-PM&#34; width=&#34;703&#34; height=&#34;742&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The state machine is essentially the set of instructions that tell NGINX how to process a request. Most web servers that perform the same functions as NGINX use a similar state machine – the difference lies in the implementation.&lt;/p&gt;

&lt;h2 id=&#34;scheduling-the-state-machine:19032429da545135790f588d1d3e4370&#34;&gt;Scheduling the State Machine&lt;/h2&gt;

&lt;p&gt;Think of the state machine like the rules for chess. Each HTTP transaction is a chess game. On one side of the chessboard is the web server – a grandmaster who can make decisions very quickly. On the other side is the remote client – the web browser that is accessing the site or application over a relatively slow network.&lt;/p&gt;

&lt;p&gt;However, the rules of the game can be very complicated. For example, the web server might need to communicate with other parties (proxying to an upstream application) or talk to an authentication server. Third-party modules in the web server can even extend the rules of the game.&lt;/p&gt;

&lt;h3 id=&#34;a-blocking-state-machine:19032429da545135790f588d1d3e4370&#34;&gt;A Blocking State Machine&lt;/h3&gt;

&lt;p&gt;Recall our description of a process or thread as a self-contained set of instructions that the operating system can schedule to run on a CPU core. Most web servers and web applications use a process-per-connection orthread-per-connection model to play the chess game. Each process or thread contains the instructions to play one game through to the end. During the time the process is run by the server, it spends most of its time ‘blocked’ – waiting for the client to complete its next move.&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1942&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/06/Screen-Shot-2015-06-08-at-12.40.52-PM.png&#34; alt=&#34;Screen-Shot-2015-06-08-at-12.40.52-PM&#34; width=&#34;373&#34; height=&#34;341&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The web server process listens for new connections (new games initiated by clients) on the listen sockets.&lt;/li&gt;
&lt;li&gt;When it gets a new game, it plays that game, blocking after each move to wait for the client’s response.&lt;/li&gt;
&lt;li&gt;Once the game completes, the web server process might wait to see if the client wants to start a new game (this corresponds to a keepalive connection). If the connection is closed (the client goes away or a timeout occurs), the web server process returns to listening for new games.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The important point to remember is that every active HTTP connection (every chess game) requires a dedicated process or thread (a grandmaster). This architecture is simple and easy to extend with third-party modules (‘new rules’). However, there’s a huge imbalance: the rather lightweight HTTP connection, represented by a file descriptor and a small amount of memory, maps to a separate thread or process, a very heavyweight operating system object. It’s a programming convenience, but it’s massively wasteful.&lt;/p&gt;

&lt;h3 id=&#34;nginx-is-a-true-grandmaster:19032429da545135790f588d1d3e4370&#34;&gt;NGINX is a True Grandmaster&lt;/h3&gt;

&lt;p&gt;Perhaps you’ve heard of &lt;a href=&#34;http://en.wikipedia.org/wiki/Simultaneous_exhibition&#34; target=&#34;_blank&#34;&gt;simultaneous exhibition&lt;/a&gt; games, where one chess grandmaster plays dozens of opponents at the same time?&lt;/p&gt;

&lt;div id=&#34;attachment_1943&#34; style=&#34;width: 490px&#34; class=&#34;wp-caption aligncenter&#34;&gt;
  &lt;img class=&#34;wp-image-1943 size-full&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/06/Kiril-Georgiev.gif&#34; alt=&#34;Kiril-Georgiev&#34; width=&#34;480&#34; height=&#34;337&#34; /&gt;
  
  &lt;p class=&#34;wp-caption-text&#34;&gt;
    Kiril Georgiev played 360 people simultaneously in Sofia, Bulgaria. His final score was 284 wins, 70 draws and 6 losses.
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;That’s how an NGINX worker process plays “chess.” Each worker (remember – there’s usually one worker for each CPU core) is a grandmaster that can play hundreds (in fact, hundreds of thousands) of games simultaneously.&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1944&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/06/Screen-Shot-2015-06-08-at-12.41.13-PM.png&#34; alt=&#34;Screen-Shot-2015-06-08-at-12.41.13-PM&#34; width=&#34;376&#34; height=&#34;355&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The worker waits for events on the listen and connection sockets.&lt;/li&gt;
&lt;li&gt;Events occur on the sockets and the worker handles them:

&lt;ul&gt;
&lt;li&gt;An event on the listen socket means that a client has started a new chess game. The worker creates a new connection socket.&lt;/li&gt;
&lt;li&gt;An event on a connection socket means that the client has made a new move. The worker responds promptly.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A worker never blocks on network traffic, waiting for its “opponent” (the client) to respond. When it has made its move, the worker immediately proceeds to other games where moves are waiting to be processed, or welcomes new players in the door.&lt;/p&gt;

&lt;h3 id=&#34;why-is-this-faster-than-a-blocking-multi-process-architecture:19032429da545135790f588d1d3e4370&#34;&gt; Why Is This Faster than a Blocking, Multi-Process Architecture?&lt;/h3&gt;

&lt;p&gt;NGINX scales very well to support hundreds of thousands of connections per worker process. Each new connection creates another file descriptor and consumes a small amount of additional memory in the worker process. There is very little additional overhead per connection. NGINX processes can remain pinned to CPUs. Context switches are relatively infrequent and occur when there is no work to be done.&lt;/p&gt;

&lt;p&gt;In the blocking, connection-per-process approach, each connection requires a large amount of additional resources and overhead, and context switches (swapping from one process to another) are very frequent.&lt;/p&gt;

&lt;p&gt;For a more detailed explanation, check out this &lt;a href=&#34;http://www.aosabook.org/en/nginx.html&#34; target=&#34;_blank&#34;&gt;article&lt;/a&gt; about NGINX architecture, by Andrew Alexeev, VP of Corporate Development and Co-Founder at NGINX, Inc.&lt;/p&gt;

&lt;p&gt;With appropriate &lt;a href=&#34;http://nginx.com/blog/tuning-nginx/&#34;&gt;system tuning&lt;/a&gt;, NGINX can scale to handle hundreds of thousands of concurrent HTTP connections per worker process, and can absorb traffic spikes (an influx of new games) without missing a beat.&lt;/p&gt;

&lt;h2 id=&#34;updating-configuration-and-upgrading-nginx:19032429da545135790f588d1d3e4370&#34;&gt;Updating Configuration and Upgrading NGINX&lt;/h2&gt;

&lt;p&gt;NGINX’s process architecture, with a small number of worker processes, makes for very efficient updating of the configuration and even the NGINX binary itself.&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1945&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/06/Screen-Shot-2015-06-08-at-12.41.33-PM.png&#34; alt=&#34;Screen-Shot-2015-06-08-at-12.41.33-PM&#34; width=&#34;729&#34; height=&#34;305&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Updating NGINX configuration is a very simple, lightweight, and reliable operation. It typically just means running the&lt;/p&gt;

&lt;div class=&#34;codecolorer-container bash blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;bash codecolorer&#34;&gt;
          nginx –s reload
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;command, which checks the configuration on disk and sends the master process a SIGHUP signal.&lt;/p&gt;

&lt;p&gt;When the master process receives a SIGHUP, it does two things:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Reloads the configuration and forks a new set of worker processes. These new worker processes immediately begin accepting connections and processing traffic (using the new configuration settings).&lt;/li&gt;
&lt;li&gt;Signals the old worker processes to gracefully exit. The worker processes stop accepting new connections. As soon as each current HTTP request completes, the worker process cleanly shuts down the connection (that is, there are no lingering keepalives). Once all connections are closed, the worker processes exit.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This reload process can cause a small spike in CPU and memory usage, but it’s generally imperceptible compared to the resource load from active connections. You can reload the configuration multiple times per second (and many NGINX users do exactly that). Very rarely, issues arise when there are many generations of NGINX worker processes waiting for connections to close, but even those are quickly resolved.&lt;/p&gt;

&lt;p&gt;NGINX’s binary upgrade process achieves the holy grail of high-availability – you can upgrade the software on the fly, without any dropped connections, downtime, or interruption in service.&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1946&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/06/Screen-Shot-2015-06-08-at-12.41.51-PM.png&#34; alt=&#34;Screen-Shot-2015-06-08-at-12.41.51-PM&#34; width=&#34;774&#34; height=&#34;284&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The binary upgrade process is similar in approach to the graceful reload of configuration. A new NGINX master process runs in parallel with the original master process, and they share the listening sockets. Both processes are active, and their respective worker processes handle traffic. You can then signal the old master and its workers to gracefully exit.&lt;/p&gt;

&lt;p&gt;The entire process is described in more detail in &lt;a href=&#34;http://nginx.org/en/docs/control.html&#34; target=&#34;_blank&#34;&gt;Controlling NGINX&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;conclusion:19032429da545135790f588d1d3e4370&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;http://nginx.com/resources/library/infographic-inside-nginx/&#34;&gt;Inside NGINX infographic&lt;/a&gt; provides a high-level overview of how NGINX functions, but behind this simple explanation is over ten years of innovation and optimization that enable NGINX to deliver the best possible performance on a wide range of hardware while maintaining the security and reliability that modern web applications require.&lt;/p&gt;

&lt;p&gt;If you’d like to read more about the optimizations in NGINX, check out these great resources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nginx.com/resources/webinars/installing-tuning-nginx/&#34;&gt;Installing and Tuning NGINX for Performance&lt;/a&gt; (webinar; &lt;a href=&#34;https://speakerdeck.com/nginx/nginx-installation-and-tuning&#34; target=&#34;_blank&#34;&gt;slides&lt;/a&gt; at Speaker Deck)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://nginx.com/blog/tuning-nginx/&#34;&gt;Tuning NGINX for Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.aosabook.org/en/nginx.html&#34; target=&#34;_blank&#34;&gt;The Architecture of Open Source Applications – NGINX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://nginx.com/blog/socket-sharding-nginx-release-1-9-1/&#34;&gt;Socket Sharding in NGINX Release 1.9.1&lt;/a&gt; (using the SO_REUSEPORT socket option)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原文：&lt;a href=&#34;http://nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&#34;&gt;http://nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Golang多版本共存方案</title>
      <link>http://:1313/tmp/2015/06/golang%E5%A4%9A%E7%89%88%E6%9C%AC%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/</link>
      <pubDate>Fri, 12 Jun 2015 08:35:04 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/06/golang%E5%A4%9A%E7%89%88%E6%9C%AC%E5%85%B1%E5%AD%98%E6%96%B9%E6%A1%88/</guid>
      <description>&lt;p&gt;如果你是一个狂热的Golang爱好者，也许你会同时使用两个或两个以上的Golang版本。那么这时候怎么实现呢？&lt;/p&gt;

&lt;p&gt;这里提供一个Russ cox的方案。这个方案是在Google Group里看到的，但是我现在已经找不到具体是哪个链接了。&lt;/p&gt;

&lt;div class=&#34;codecolorer-container bash blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;bash codecolorer&#34;&gt;
          &lt;span class=&#34;co0&#34;&gt;#file:/usr/bin/go1.4&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;co0&#34;&gt;#!/bin/bash&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw3&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;re2&#34;&gt;GOROOT&lt;/span&gt;=&lt;span class=&#34;re1&#34;&gt;$HOME&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;go1.4&lt;br /&gt; &lt;span class=&#34;kw3&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;re2&#34;&gt;PATH&lt;/span&gt;=&lt;span class=&#34;re1&#34;&gt;$HOME&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;go1.4&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;bin:&lt;span class=&#34;re1&#34;&gt;$PATH&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw3&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;re1&#34;&gt;$GOROOT&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;bin&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;go &lt;span class=&#34;st0&#34;&gt;&#34;$@&#34;&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;历史稳定版本可以这样处理，然后把开发版本作为默认的。&lt;/p&gt;

&lt;p&gt;all done.&lt;/p&gt;

&lt;p&gt;另：&lt;a href=&#34;https://twitter.com/_rsc&#34;&gt;Russ cox &lt;/a&gt;已经成为我的偶像啦&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>分享自己用Golang写的一个Web bench 工具</title>
      <link>http://:1313/tmp/2015/06/%E5%88%86%E4%BA%AB%E8%87%AA%E5%B7%B1%E7%94%A8golang%E5%86%99%E7%9A%84%E4%B8%80%E4%B8%AAweb-bench-%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Wed, 10 Jun 2015 12:49:08 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/06/%E5%88%86%E4%BA%AB%E8%87%AA%E5%B7%B1%E7%94%A8golang%E5%86%99%E7%9A%84%E4%B8%80%E4%B8%AAweb-bench-%E5%B7%A5%E5%85%B7/</guid>
      <description>&lt;p&gt;最近一直在学习Golang，业余时间开了个Web bench 工具awb，awb是another web bench的缩写，基本功能已完成，兼容ab的参数。&lt;/p&gt;

&lt;p&gt;初步测试并发性比ab要好一些。感觉Golang除了在服务端开发方面有很大的优势以外，在写各类工具方面也是挺方便顺手的。估计未来会有很多写的运维工具使用Golang 编写。&lt;/p&gt;

&lt;p&gt;总体上来说Go非常符合我的胃口。既有PHP的简洁、高效，在性能、并发、异步方面又有很好的系统级别的支持。整体上很有当年第一次看到PHP的时候的感觉。。。心动不已啊 &lt;img src=&#34;http://blog.webfuns.net/wp-includes/images/smilies/simple-smile.png&#34; alt=&#34;:)&#34; class=&#34;wp-smiley&#34; style=&#34;height: 1em; max-height: 1em;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;项目地址：&lt;a href=&#34;https://github.com/tomheng/awb&#34;&gt;https://github.com/tomheng/awb&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[转]How does the Go runtime work?</title>
      <link>http://:1313/tmp/2015/06/%E8%BD%AChow-does-the-go-runtime-work/</link>
      <pubDate>Wed, 10 Jun 2015 10:25:02 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/06/%E8%BD%AChow-does-the-go-runtime-work/</guid>
      <description>&lt;p&gt;(This answer is for the Go compiler from golang.org. It is not about gccgo.)&lt;/p&gt;

&lt;p&gt;The Go runtime is a Go package, which appears (in the documentation, the build process, the things it exports) to be like any other Go package. It is written in a combination of Go, C, and assembly. In order for it to do all the low level things it needs to do, there are special adaptations (hacks?) in the build system and in the compiler that are activated when compiling it. The runtime has architecture- and OS-specific things in it, which are compiled in according the the target platform.&lt;/p&gt;

&lt;p&gt;At linking time, the linker creates a statically linked ELF (or PE or MachO) file which includes the runtime, your program, and every package that your program references. The starting address in the ELF header points into the runtime. It arranges for it&amp;#8217;s own data structures to be initialized, then calls the initializers of all the packages (ordering of init is probably figured out at link time by the linker). It then transfers control to main.main, and your program is running. (There are situations where Go creates dynamically linked executables, but the majority of the code is still statically linked.)&lt;/p&gt;

&lt;p&gt;When your program does things that could cause a crash, like a cast, or accessing an item in an array, the compiler emits calls into the runtime, which checks the data type with run time type info, or checks the bounds of the array. Likewise for memory allocation and for creating new goroutines, the runtime gets control. The runtime has a user-space scheduler in it, which implements cooperative multitasking; if a goroutine goes into a tight loop without calling any routines that would block (thereby giving the scheduler control) it can starve all the other goroutines. The runtime spawns a new system thread when needed to prevent the system from blocking on system calls. There can be fewer system threads in a Go system than the number of goroutines that are active.&lt;/p&gt;

&lt;p&gt;The final aspect of the Go runtime that is very interesting is the per-goroutine stack. The runtime, together with the linker, arranges for the hardware stack to be non-contiguous, able to grow and shrink according to demand. As the stack shrinks after growing, it is freed and is available to be realloced as other types of objects by the memory allocator. This allows Go stacks to start very small (8 k), meaning that a Go program can launch hundreds of thousands of Goroutines without running out of address space. (The stack is becoming continuous in Go 1.5 but it can still be reallocated and moved when it runs out.)&lt;/p&gt;

&lt;p&gt;When programming Go, the runtime is not in the front of your mind. You interact with the system library, and the runtime supports your code more or less silently. This is why the majority of information you&amp;#8217;ll see about Go is how to use the libraries and how to use the channels to implement concurrent programming, and little about the runtime itself.&lt;/p&gt;

&lt;p&gt;原文：&lt;a href=&#34;http://www.quora.com/How-does-the-Go-runtime-work&#34;&gt;http://www.quora.com/How-does-the-Go-runtime-work&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Golang 使用心得-正确关闭channel</title>
      <link>http://:1313/tmp/2015/06/golang-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97-%E6%AD%A3%E7%A1%AE%E5%85%B3%E9%97%ADchannel/</link>
      <pubDate>Tue, 02 Jun 2015 13:48:36 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/06/golang-%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97-%E6%AD%A3%E7%A1%AE%E5%85%B3%E9%97%ADchannel/</guid>
      <description>&lt;p&gt;相信很多同学都是因为Golang有相当简单的并发模型才转过来的。Golang的并发模型主要由三部分构成：Goroutine、Channel和Select。&lt;/p&gt;

&lt;p&gt;其中Channel是Goroutine之间通信的桥梁，简单优雅的解决了并行开发中的同步问题。&lt;/p&gt;

&lt;p&gt;但是初学者（比如我）通常会遇到** send on closed channel**的错误，这是因为我们向一个已经关闭channle推送数据造成的。通常这个错误是发生在生成消费模型中。channel用来传送需要执行的任务，channel一端是生产者，另一端是消费者。&lt;/p&gt;

&lt;p&gt;如下代码：&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;8&lt;br /&gt;9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;br /&gt;13&lt;br /&gt;14&lt;br /&gt;15&lt;br /&gt;16&lt;br /&gt;17&lt;br /&gt;18&lt;br /&gt;19&lt;br /&gt;20&lt;br /&gt;21&lt;br /&gt;22&lt;br /&gt;23&lt;br /&gt;24&lt;br /&gt;25&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;kw1&#34;&gt;package&lt;/span&gt; main&lt;br /&gt; &lt;br /&gt; &lt;span class=&#34;kw1&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;st0&#34;&gt;&#34;fmt&#34;&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;st0&#34;&gt;&#34;sync&#34;&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; main&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; jobs &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kw3&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw4&#34;&gt;chan&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;var&lt;/span&gt; wg sync&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;WaitGroup&lt;br /&gt; &amp;nbsp; &amp;nbsp; wg&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Add&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt; &lt; &lt;span class=&#34;nu0&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;sy2&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; jobs &lt;&lt;span class=&#34;sy3&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; fmt&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Println&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;produce:&#34;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt; &amp;nbsp; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}()&lt;/span&gt; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kw1&#34;&gt;range&lt;/span&gt; jobs &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; fmt&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Println&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;consume:&#34;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; i&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; wg&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;me1&#34;&gt;Done&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt; &amp;nbsp; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}()&lt;/span&gt; &lt;br /&gt; &amp;nbsp; &amp;nbsp; wg&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;me1&#34;&gt;Wait&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;注意上面的代码我们没有主动关闭channel，因为我一开始就知道执行的任务数，所以直接等待任务完成即可，没有必要主动关闭channel。&lt;/p&gt;

&lt;p&gt;假设我们的场景中，生产者没有生成数量的限制，只有一个时间限制。那么代码演变成下面这样：&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;8&lt;br /&gt;9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;br /&gt;13&lt;br /&gt;14&lt;br /&gt;15&lt;br /&gt;16&lt;br /&gt;17&lt;br /&gt;18&lt;br /&gt;19&lt;br /&gt;20&lt;br /&gt;21&lt;br /&gt;22&lt;br /&gt;23&lt;br /&gt;24&lt;br /&gt;25&lt;br /&gt;26&lt;br /&gt;27&lt;br /&gt;28&lt;br /&gt;29&lt;br /&gt;30&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;kw1&#34;&gt;package&lt;/span&gt; main&lt;br /&gt; &lt;br /&gt; &lt;span class=&#34;kw1&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;st0&#34;&gt;&#34;fmt&#34;&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;st0&#34;&gt;&#34;sync&#34;&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;st0&#34;&gt;&#34;time&#34;&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; main&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; jobs &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kw3&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw4&#34;&gt;chan&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;var&lt;/span&gt; wg sync&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;WaitGroup&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; time&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Sleep&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;time&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Second &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw3&#34;&gt;close&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;jobs&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}()&lt;/span&gt; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;sy2&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; jobs &lt;&lt;span class=&#34;sy3&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; fmt&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Println&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;produce:&#34;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt; &amp;nbsp; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}()&lt;/span&gt; &lt;br /&gt; &amp;nbsp; &amp;nbsp; wg&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Add&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;defer&lt;/span&gt; wg&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Done&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kw1&#34;&gt;range&lt;/span&gt; jobs &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; fmt&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Println&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;consume:&#34;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; i&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt; &amp;nbsp; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}()&lt;/span&gt; &lt;br /&gt; &amp;nbsp; &amp;nbsp; wg&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;me1&#34;&gt;Wait&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;这时程序就会因为&lt;strong&gt;send on closed channel&lt;/strong&gt;而崩溃。那么首先想到的解决方案可能是在放入jobs的时候检查jobs是否已关闭。幸好Golang有办法来检测channel是否被关闭，但是非常不好用。Golang中可以用comma ok的方式检测channel是否关闭，如下：&lt;/p&gt;

&lt;p&gt;i, ok := &amp;lt;- jobs 如果channel关闭那么ok返回的是false，但是这样的话，如果jobs没有关闭，那么就会漏掉一个job。当然你可以想办好hack掉漏掉的这个job。但是这样的代码不是很优雅，也是那么直观合理。 在实践中我是用的如下代码处理这个问题。&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;8&lt;br /&gt;9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;br /&gt;13&lt;br /&gt;14&lt;br /&gt;15&lt;br /&gt;16&lt;br /&gt;17&lt;br /&gt;18&lt;br /&gt;19&lt;br /&gt;20&lt;br /&gt;21&lt;br /&gt;22&lt;br /&gt;23&lt;br /&gt;24&lt;br /&gt;25&lt;br /&gt;26&lt;br /&gt;27&lt;br /&gt;28&lt;br /&gt;29&lt;br /&gt;30&lt;br /&gt;31&lt;br /&gt;32&lt;br /&gt;33&lt;br /&gt;34&lt;br /&gt;35&lt;br /&gt;36&lt;br /&gt;37&lt;br /&gt;38&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;kw1&#34;&gt;package&lt;/span&gt; main&lt;br /&gt; &lt;br /&gt; &lt;span class=&#34;kw1&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;st0&#34;&gt;&#34;fmt&#34;&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;st0&#34;&gt;&#34;sync&#34;&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;st0&#34;&gt;&#34;time&#34;&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; main&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; jobs &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kw3&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw4&#34;&gt;chan&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;var&lt;/span&gt; wg sync&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;WaitGroup&lt;br /&gt; &amp;nbsp; &amp;nbsp; timeout &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kw3&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kw4&#34;&gt;chan&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;bool&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; time&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Sleep&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;time&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Second &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; timeout &lt;&lt;span class=&#34;sy3&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;kw2&#34;&gt;true&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}()&lt;/span&gt; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;sy2&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;case&lt;/span&gt; &lt;&lt;span class=&#34;sy3&#34;&gt;-&lt;/span&gt;timeout&lt;span class=&#34;sy1&#34;&gt;:&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw3&#34;&gt;close&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;jobs&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;return&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;:&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; jobs &lt;&lt;span class=&#34;sy3&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; fmt&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Println&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;produce:&#34;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt; &amp;nbsp; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt; &amp;nbsp; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}()&lt;/span&gt; &lt;br /&gt; &amp;nbsp; &amp;nbsp; wg&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Add&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;defer&lt;/span&gt; wg&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Done&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kw1&#34;&gt;range&lt;/span&gt; jobs &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; fmt&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;Println&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;consume:&#34;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; i&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt; &amp;nbsp; &lt;br /&gt; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}()&lt;/span&gt; &lt;br /&gt; &amp;nbsp; &amp;nbsp; wg&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;me1&#34;&gt;Wait&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;()&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;实际情况可能还要复杂很多，比如会有多个生产者，这个时候代码又该如何处理呢？大家可以想一想。。。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>致青春</title>
      <link>http://:1313/tmp/2015/05/%E8%87%B4%E9%9D%92%E6%98%A5/</link>
      <pubDate>Thu, 07 May 2015 01:59:50 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/05/%E8%87%B4%E9%9D%92%E6%98%A5/</guid>
      <description>&lt;p&gt;五四青年节公司组织的活动，用一句话寄语青春。想了一下突然在脑子冒出这么一句话：“青春是一场不知何时开始的美梦，却在最意犹未尽时醒来”。&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1923&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/05/microMsg.1430717969910.jpg&#34; alt=&#34;microMsg.1430717969910&#34; width=&#34;1840&#34; height=&#34;3264&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[转]Go Data Structures</title>
      <link>http://:1313/tmp/2015/04/%E8%BD%ACgo-data-structures/</link>
      <pubDate>Thu, 30 Apr 2015 14:46:43 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/04/%E8%BD%ACgo-data-structures/</guid>
      <description>

&lt;p class=&#34;lp&#34;&gt;
  When explaining Go to new programmers, I&amp;#8217;ve found that it often helps to explain what Go values look like in memory, to build the right intuition about which operations are expensive and which are not. This post is about basic types, structs, arrays, and slices.
&lt;/p&gt;

&lt;h2 id=&#34;basic-types:b059c0fef419e9705bbdc8ad0002c1c2&#34;&gt;Basic types&lt;/h2&gt;

&lt;p&gt;Let&amp;#8217;s start with some simple examples:&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  &lt;img class=&#34;aligncenter size-full wp-image-1913&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/godata1.png&#34; alt=&#34;godata1&#34; width=&#34;409&#34; height=&#34;303&#34; /&gt;
&lt;/p&gt;

&lt;p class=&#34;lp&#34;&gt;
  The variable &lt;em&gt;i&lt;/em&gt; has type &lt;em&gt;int&lt;/em&gt;, represented in memory as a single 32-bit word. (All these pictures show a 32-bit memory layout; in the current implementations, only the pointer gets bigger on a 64-bit machine—&lt;em&gt;int&lt;/em&gt; is still 32 bits—though an implementation could choose to use 64 bits instead.)
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  The variable &lt;em&gt;j&lt;/em&gt; has type &lt;em&gt;int32&lt;/em&gt;, because of the explicit conversion. Even though &lt;em&gt;i&lt;/em&gt; and &lt;em&gt;j&lt;/em&gt; have the same memory layout, they have different types: the assignment &lt;em&gt;i = j&lt;/em&gt; is a type error and must be written with an explicit conversion: &lt;em&gt;i = int(j)&lt;/em&gt;.
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  The variable &lt;em&gt;f&lt;/em&gt; has type &lt;em&gt;float&lt;/em&gt;, which the current implementations represent as a 32-bit floating-point value. It has the same memory footprint as the &lt;em&gt;int32&lt;/em&gt; but a different internal layout.
&lt;/p&gt;

&lt;h2 id=&#34;structs-and-pointers:b059c0fef419e9705bbdc8ad0002c1c2&#34;&gt;Structs and pointers&lt;/h2&gt;

&lt;p class=&#34;pp&#34;&gt;
  Now things start to pick up. The variable &lt;em&gt;bytes&lt;/em&gt; has type &lt;em&gt;[5]byte&lt;/em&gt;, an array of 5 &lt;em&gt;byte&lt;/em&gt;s. Its memory representation is just those 5 bytes, one after the other, like a C array. Similarly, &lt;em&gt;primes&lt;/em&gt;is an array of 4 &lt;em&gt;int&lt;/em&gt;s.
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  Go, like C but unlike Java, gives the programmer control over what is and is not a pointer. For example, this type definition:
&lt;/p&gt;

&lt;pre class=&#34;indent&#34;&gt;type Point struct { X, Y int }
&lt;/pre&gt;

&lt;p class=&#34;lp&#34;&gt;
  defines a simple struct type named &lt;em&gt;Point&lt;/em&gt;, represented as two adjacent &lt;em&gt;int&lt;/em&gt;s in memory.
&lt;/p&gt;

&lt;p class=&#34;lp&#34;&gt;
  &lt;img class=&#34;aligncenter size-full wp-image-1914&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/godata1a.png&#34; alt=&#34;godata1a&#34; width=&#34;285&#34; height=&#34;151&#34; /&gt;
&lt;/p&gt;

&lt;p class=&#34;lp&#34;&gt;
  The &lt;a href=&#34;http://golang.org/doc/go_spec.html#Composite_literals&#34;&gt;composite literal syntax&lt;/a&gt; &lt;em&gt;Point{10, 20}&lt;/em&gt; denotes an initialized &lt;em&gt;Point&lt;/em&gt;. Taking the address of a composite literal denotes a pointer to a freshly allocated and initialized &lt;em&gt;Point&lt;/em&gt;. The former is two words in memory; the latter is a pointer to two words in memory.
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  Fields in a struct are laid out side by side in memory.
&lt;/p&gt;

&lt;pre class=&#34;indent&#34;&gt;type Rect1 struct { Min, Max Point }
type Rect2 struct { Min, Max *Point }&lt;/pre&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1915&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/godata1b.png&#34; alt=&#34;godata1b&#34; width=&#34;443&#34; height=&#34;151&#34; /&gt;&lt;/p&gt;

&lt;p class=&#34;lp&#34;&gt;
  &lt;em&gt;Rect1&lt;/em&gt;, a struct with two &lt;em&gt;Point&lt;/em&gt; fields, is represented by two &lt;em&gt;Point&lt;/em&gt;s—four ints—in a row. &lt;em&gt;Rect2&lt;/em&gt;, a struct with two &lt;em&gt;*Point&lt;/em&gt; fields, is represented by two &lt;em&gt;*Point&lt;/em&gt;s.
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  Programmers who have used C probably won&amp;#8217;t be surprised by the distinction between &lt;em&gt;Point&lt;/em&gt; fields and &lt;em&gt;*Point&lt;/em&gt; fields, while programmers who have only used Java or Python (or &amp;#8230;) may be surprised by having to make the decision. By giving the programmer control over basic memory layout, Go provides the ability to control the total size of a given collection of data structures, the number of allocations, and the memory access patterns, all of which are important for building systems that perform well.
&lt;/p&gt;

&lt;h2 id=&#34;strings:b059c0fef419e9705bbdc8ad0002c1c2&#34;&gt;Strings&lt;/h2&gt;

&lt;p class=&#34;pp&#34;&gt;
  With those preliminaries, we can move on to more interesting data types.
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  &lt;img class=&#34;aligncenter size-full wp-image-1916&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/godata2.png&#34; alt=&#34;godata2&#34; width=&#34;264&#34; height=&#34;151&#34; /&gt;
&lt;/p&gt;

&lt;p class=&#34;lp&#34;&gt;
  (The gray arrows denote pointers that are present in the implementation but not directly visible in programs.)
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  A &lt;em&gt;string&lt;/em&gt; is represented in memory as a 2-word structure containing a pointer to the string data and a length. Because the &lt;em&gt;string&lt;/em&gt; is immutable, it is safe for multiple strings to share the same storage, so &lt;a href=&#34;http://www.blogger.com/post-edit.g?blogID=8082954141980125536&amp;postID=65253524121904390&#34;&gt;slicing&lt;/a&gt; &lt;em&gt;s&lt;/em&gt; results in a new 2-word structure with a potentially different pointer and length that still refers to the same byte sequence. This means that slicing can be done without allocation or copying, making string slices as efficient as passing around explicit indexes.
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  (As an aside, there is a &lt;a href=&#34;http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4513622&#34;&gt;well-known gotcha&lt;/a&gt; in Java and other languages that when you slice a string to save a small piece, the reference to the original keeps the entire original string in memory even though only a small amount is still needed. Go has this gotcha too. The alternative, which we tried &lt;a href=&#34;http://code.google.com/p/go/source/detail?r=70fa38e5a5bb&#34;&gt;and rejected&lt;/a&gt;, is to make string slicing so expensive—an allocation and a copy—that most programs avoid it.)
&lt;/p&gt;

&lt;h2 id=&#34;slices:b059c0fef419e9705bbdc8ad0002c1c2&#34;&gt;Slices&lt;/h2&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1917&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/godata3.png&#34; alt=&#34;godata3&#34; width=&#34;470&#34; height=&#34;151&#34; /&gt;&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  A &lt;a href=&#34;http://golang.org/doc/effective_go.html#slices&#34;&gt;slice&lt;/a&gt; is a reference to a section of an array. In memory, it is a 3-word structure contaning a pointer to the first element, the length of the slice, and the capacity. The length is the upper bound for indexing operations like &lt;em&gt;x[i]&lt;/em&gt; while the capacity is the upper bound for slice operations like &lt;em&gt;x[i:j]&lt;/em&gt;.
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  Like slicing a string, slicing an array does not make a copy: it only creates a new structure holding a different pointer, length, and capacity. In the example, evaluating the composite literal&lt;em&gt;[]int{2, 3, 5, 7, 11}&lt;/em&gt; creates a new array containing the five values and then sets the fields of the slice &lt;em&gt;x&lt;/em&gt; to describe that array. The slice expression &lt;em&gt;x[1:3]&lt;/em&gt; does not allocate more data: it just writes the fields of a new slice structure to refer to the same backing store. In the example, the length is 2—&lt;em&gt;y[0]&lt;/em&gt; and &lt;em&gt;y[1]&lt;/em&gt; are the only valid indexes—but the capacity is 4—&lt;em&gt;y[0:4]&lt;/em&gt; is a valid slice expression. (See &lt;a href=&#34;http://golang.org/doc/effective_go.html#slices&#34;&gt;Effective Go&lt;/a&gt; for more about length and capacity and how slices are used.)
&lt;/p&gt;

&lt;p&gt;Because slices are multiword structures, not pointers, the slicing operation does not need to allocate memory, not even for the slice header, which can usually be kept on the stack. This representation makes slices about as cheap to use as passing around explicit pointer and length pairs in C. Go originally represented a slice as a pointer to the structure shown above, but doing so meant that every slice operation allocated a new memory object. Even with a fast allocator, that creates a lot of unnecessary work for the garbage collector, and we found that, as was the case with strings above, programs avoided slicing operations in favor of passing explicit indices. Removing the indirection and the allocation made slices cheap enough to avoid passing explicit indices in most cases.&lt;/p&gt;

&lt;h2 id=&#34;new-and-make:b059c0fef419e9705bbdc8ad0002c1c2&#34;&gt;New and Make&lt;/h2&gt;

&lt;p class=&#34;pp&#34;&gt;
  Go has two data structure creation functions: &lt;em&gt;new&lt;/em&gt; and &lt;em&gt;make&lt;/em&gt;. The distinction is a common early point of confusion but seems to quickly become natural. The basic distinction is that&lt;em&gt;new(T)&lt;/em&gt; returns a &lt;em&gt;*T&lt;/em&gt;, a pointer that Go programs can dereference implicitly (the black pointers in the diagrams), while &lt;em&gt;make(T, &lt;/em&gt;&lt;i&gt;args&lt;/i&gt;&lt;em&gt;)&lt;/em&gt; returns an ordinary &lt;em&gt;T&lt;/em&gt;, not a pointer. Often that &lt;em&gt;T&lt;/em&gt; has inside it some implicit pointers (the gray pointers in the diagrams). &lt;em&gt;New&lt;/em&gt; returns a pointer to zeroed memory, while &lt;em&gt;make&lt;/em&gt; returns a complex structure.
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  &lt;img class=&#34;aligncenter size-full wp-image-1918&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/godata4.png&#34; alt=&#34;godata4&#34; width=&#34;470&#34; height=&#34;627&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;There is a way to unify these two, but it would be a significant break from the C and C++ tradition: define &lt;em&gt;make(*T)&lt;/em&gt; to return a pointer to a newly allocated &lt;em&gt;T&lt;/em&gt;, so that the current&lt;em&gt;new(Point)&lt;/em&gt; would be written &lt;em&gt;make(*Point)&lt;/em&gt;. We tried this for a few days but decided it was too different from what people expected of an allocation function.&lt;/p&gt;

&lt;h2 id=&#34;coming-soon-8230:b059c0fef419e9705bbdc8ad0002c1c2&#34;&gt;Coming soon&amp;#8230;&lt;/h2&gt;

&lt;p class=&#34;pp&#34;&gt;
  This has already gotten a bit long. Interface values, maps, and channels will have to wait for future posts.
&lt;/p&gt;

&lt;p class=&#34;pp&#34;&gt;
  原文：http://research.swtch.com/godata
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[转]GC学习笔记</title>
      <link>http://:1313/tmp/2015/04/%E8%BD%ACgc%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 28 Apr 2015 10:35:51 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/04/%E8%BD%ACgc%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>

&lt;p&gt;这是我公司同事的GC学习笔记，写得蛮详细的，由浅入深，循序渐进，让人一看就懂，特转到这里。&lt;/p&gt;

&lt;p&gt;一、GC特性以及各种GC的选择&lt;br /&gt;
1、垃圾回收器的特性&lt;br /&gt;
2、对垃圾回收器的选择&lt;br /&gt;
2.1 连续 VS. 并行&lt;br /&gt;
2.2 并发 VS. stop-the-world&lt;br /&gt;
2.3 压缩 VS. 不压缩 VS. 复制&lt;br /&gt;
二、GC性能指标&lt;br /&gt;
三、分代回收&lt;br /&gt;
四、J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; 分代、GC类型、快速分配&lt;br /&gt;
五、J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; SerialGC&lt;br /&gt;
六、J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; ParallelGC&lt;br /&gt;
七、J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; ParallelCompactingGC&lt;br /&gt;
八、J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; CMS GC&lt;br /&gt;
九、启动参数学习示例&lt;/p&gt;

&lt;h3 id=&#34;1-gc特性以及各种gc的选择:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;1. GC特性以及各种GC的选择&lt;/h3&gt;

&lt;h4 id=&#34;1-1-垃圾回收器的特性:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;1.1 垃圾回收器的特性&lt;/h4&gt;

&lt;p&gt;该回收的对象一定要回收，不该回收的对象一定不能回收&lt;br /&gt;
一定要有效，并且要快！尽可能少的暂停应用的运行&lt;br /&gt;
需要在时间，空间，回收频率这三个要素中平衡&lt;br /&gt;
内存碎片的问题（一种解决内存碎片的方法，就是压缩）&lt;br /&gt;
可扩展性和可伸缩性（内存的分配和回收，不应该成为跑在多核多线程应用上的瓶颈）&lt;br /&gt;
对垃圾回收器的选择&lt;/p&gt;

&lt;h4 id=&#34;1-2-连续-vs-并行:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;1.2 连续 VS. 并行&lt;/h4&gt;

&lt;p&gt;连续垃圾回收器，即使在多核的应用中，在回收时，也只有一个核被利用。&lt;br /&gt;
但并行GC会使用多核，GC任务会被分离成多个子任务，然后这些子任务在各个CPU上并行执行。&lt;br /&gt;
并行GC的好处是让GC的时间减少，但缺点是增加了复杂度，并且存在产生内存碎片的可能。&lt;/p&gt;

&lt;h4 id=&#34;1-3-并发-vs-stop-the-world:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;1.3 并发 VS. stop-the-world&lt;/h4&gt;

&lt;p&gt;当使用stop-the-world 方式的GC在执行时，整个应用会暂停住的。&lt;br /&gt;
而并发是指GC可以和应用一起执行，不用stop the world。&lt;br /&gt;
一般的说，并发GC可以做到大部分的运行时间，是可以和应用并发的，但还是有一些小任务，不得不短暂的stop the world。&lt;br /&gt;
stop the world 的GC相对简单，因为heap被冻结，对象的活动也已经停止。但缺点是可能不太满足对实时性要求很高的应用。&lt;br /&gt;
相应的，并发GC的stop the world时间非常短，并且需要做一些额外的事情，因为并发的时候，对象的引用状态有可能发生改变的。&lt;br /&gt;
所以，并发GC需要花费更多的时间，并且需要较大的heap。&lt;/p&gt;

&lt;h4 id=&#34;1-4-压缩-vs-不压缩-vs-复制:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;1.4 压缩 VS. 不压缩 VS. 复制&lt;/h4&gt;

&lt;p&gt;在GC确定内存中哪些是有用的对象，哪些是可回收的对象之后，他就可以压缩内存，把拥有的对象放到一起，并把剩下的内存进行清理。&lt;br /&gt;
在压缩之后，分配对象就会快很多，并且内存指针可以很快的指向下一个要分配的内存地址。&lt;br /&gt;
一个不压缩的GC，就原地把不被引用的对象回收，他并没有对内存进行压缩。好处就是回收的速度变快了；缺点呢，就是产生了碎片。&lt;br /&gt;
一般来说，在有碎片的内存上分配一个对象的代价要远远大于在没有碎片的内存上分配。&lt;br /&gt;
另外的选择是使用一个复制算法的GC，他是把所有被引用的对象复制到另外一个内存区域中。&lt;br /&gt;
使用复制GC的好处就是，原来的内存区域，就可以被毫无顾忌的清空了。但缺点也很明显，需要更多的内存，以及额外的时间来复制。&lt;/p&gt;

&lt;h3 id=&#34;2-gc性能指标:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;2. GC性能指标&lt;/h3&gt;

&lt;p&gt;几个评估GC性能的指标&lt;br /&gt;
吞吐量 应用花在非GC上的时间百分比&lt;br /&gt;
GC负荷 与吞吐量相反，指应用花在GC上的时间百分比&lt;br /&gt;
暂停时间 应用花在GC stop-the-world 的时间&lt;br /&gt;
GC频率 顾名思义&lt;br /&gt;
Footprint 一些资源大小的测量，比如堆的大小&lt;br /&gt;
反应速度 从一个对象变成垃圾道这个对象被回收的时间&lt;br /&gt;
一个交互式的应用要求暂停时间越少越好，然而，一个非交互性的应用，当然是希望GC负荷越低越好。&lt;br /&gt;
一个实时系统对暂停时间和GC负荷的要求，都是越低越好。&lt;br /&gt;
一个嵌入式系统当然希望Footprint越小越好。&lt;/p&gt;

&lt;h3 id=&#34;3-分代回收:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;3. 分代回收&lt;/h3&gt;

&lt;h4 id=&#34;3-1-什么是分代:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;3.1 什么是分代&lt;/h4&gt;

&lt;p&gt;当使用分代回收技术，内存会被分为几个代（generation）。也就是说，按照对象存活的年龄，把对象放到不同的代中。&lt;br /&gt;
使用最广泛的代，应属年轻代和年老代了。&lt;br /&gt;
根据各种GC算法的特征，可以相应的被应用到不同的代中。&lt;br /&gt;
研究发现：&lt;br /&gt;
大部分的对象在分配后不久，就不被引用了。也就是，他们在很早就挂了。&lt;br /&gt;
只有很少的对象熬过来了。&lt;br /&gt;
年轻代的GC相当的频繁，高效率并且快。因为年轻代通常比较小，并且很多对象都是不被引用的。&lt;br /&gt;
如果年轻代的对象熬过来了，那么就晋级到年老代中了。如图：&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1898&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/0_1302698633x4qU.png&#34; alt=&#34;0_1302698633x4qU&#34; width=&#34;412&#34; height=&#34;351&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通常年老代要比年轻代大，而且增长也比较慢。所以GC在年老代发生的频率非常低，不过一旦发生，就会占据较长的时间。&lt;/p&gt;

&lt;h4 id=&#34;3-2-总结:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;3.2 总结&lt;/h4&gt;

&lt;p&gt;年轻代通常使用时间占优的GC，因为年轻代的GC非常频繁&lt;br /&gt;
年老代通常使用善于处理大空间的GC，因为年老代的空间大，GC频率低&lt;/p&gt;

&lt;h3 id=&#34;4-j2se-5-0的hotspot-jvm上的gc学习-8211-分代-gc类型-快速分配:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;4. J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; 分代、GC类型、快速分配&lt;/h3&gt;

&lt;p&gt;J2SE5.0 update 6 的HotSpot上有4个GC。&lt;/p&gt;

&lt;h4 id=&#34;4-1-hotspot上的分代:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;4.1 HotSpot上的分代&lt;/h4&gt;

&lt;p&gt;分成三部分：年轻代、年老代、永久代&lt;br /&gt;
很多的对象一开始是分配在年轻代的，这些对象在熬过了一定次数的young gc之后，就进入了年老代。同时，一些比较大的对象，一开始就可能被直接分配到年老代中（因为年轻代比较小嘛）。&lt;/p&gt;

&lt;h4 id=&#34;4-2-年轻代:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;4.2 年轻代&lt;/h4&gt;

&lt;p&gt;年轻代也进行划分，划分成：一个Eden和两个survivor。如下图：&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1901&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/0_130269864310w6.png&#34; alt=&#34;0_130269864310w6&#34; width=&#34;529&#34; height=&#34;309&#34; /&gt;&lt;/p&gt;

&lt;p&gt;大部分的对象被直接分配到年轻代的eden区（之前已经提到了是，很大的对象会被直接分配到年老代中），&lt;br /&gt;
survivor区里面放至少熬过一个YGC的对象，在survivor里面的对象，才有机会被考虑提升到年老代中。&lt;br /&gt;
同一时刻，两个survivor只被使用一个，另外一个是用来进行复制GC时使用的。&lt;/p&gt;

&lt;h4 id=&#34;4-3-gc类型:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;4.3 GC类型&lt;/h4&gt;

&lt;p&gt;年轻代的GC叫young GC，有时候也叫 minor GC。年老代或者永久代的GC，叫 full GC，也叫major GC。&lt;br /&gt;
也就是说，所有的代都会进行GC。&lt;br /&gt;
一般的，首先是进行年轻代的GC，（使用针对年轻代的GC），然后是年老代和永久代使用相同的GC。如果要压缩（解决内存碎片问题），每个代需要分别压缩。&lt;br /&gt;
有时候，如果年老区本身就已经很满了，满到无法放下从survivor熬出来的对象，那么，YGC就不会再次触发，而是会使用FullGC对整个堆进行GC（除了CMS这种GC，因为CMS不能对年轻代进行GC）&lt;/p&gt;

&lt;h4 id=&#34;4-4-快速分配内存:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;4.4 快速分配内存&lt;/h4&gt;

&lt;p&gt;多线程进行对象建立的时候，在为对象分配内存的时候，就应该保证线程安全，为此，就应该进入全局锁。但全局锁是非常消耗性能的。&lt;br /&gt;
为此，HotSpot引入了Thread Local Allocation Buffers （TLAB）技术，这种技术的原理就是为每个线程分配一个缓冲，用来分配线程自己的对象。&lt;br /&gt;
每个线程只使用自己的TLAB，这样，就保证了不用使用全局锁。当TLAB不够用的时候，才需要使用全局锁。但这时候对锁的时候，频率已经相当的低了。&lt;br /&gt;
为了减少TLAB对空间的消耗，分配器也想了很多方法，平均来说，TLAB占用Eden区的不到1%。&lt;/p&gt;

&lt;h3 id=&#34;5-j2se-5-0的hotspot-jvm上的gc学习-8211-serialgc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;5. J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; SerialGC&lt;/h3&gt;

&lt;h4 id=&#34;5-1-串行gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;5.1 串行GC&lt;/h4&gt;

&lt;p&gt;串行GC，只使用单个CPU，并且会stop the world。&lt;/p&gt;

&lt;h5 id=&#34;5-1-1-young-的串行gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;5.1.1 young 的串行GC&lt;/h5&gt;

&lt;p&gt;如下图：&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1902&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/0_13026986774jY9.png&#34; alt=&#34;0_13026986774jY9&#34; width=&#34;538&#34; height=&#34;282&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当发生ygc的时候，Eden和From的survivor区会将被引用的对象复制到To这个survivor种。&lt;br /&gt;
如果有些对象在To survivor放不下，则直接升级到年老区。&lt;br /&gt;
当YGC完成后，内存情况如下图：&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1903&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/0_1302698666kzzx.png&#34; alt=&#34;0_1302698666kzzx&#34; width=&#34;536&#34; height=&#34;349&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;5-1-2-old区的串行gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;5.1.2 old区的串行GC&lt;/h5&gt;

&lt;p&gt;年老区和永久区使用的是Mark-Sweep-Compact的算法。&lt;br /&gt;
mark阶段是对有引用的对象进行标识&lt;br /&gt;
sweep是对垃圾进行清理&lt;br /&gt;
compact对把活着的对象进行迁移，解决内存碎片的问题&lt;br /&gt;
如下图：&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1902&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/0_13026986774jY9.png&#34; alt=&#34;0_13026986774jY9&#34; width=&#34;538&#34; height=&#34;282&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;5-2-何时使用串行收集器:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;5.2 何时使用串行收集器&lt;/h4&gt;

&lt;p&gt;串行GC适用于对暂停时间要求不严，在客户端下使用。&lt;/p&gt;

&lt;h4 id=&#34;5-3-串行收集器的选择:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;5.3 串行收集器的选择&lt;/h4&gt;

&lt;p&gt;在J2SE5.0上，在非 server 模式下，JVM自动选择串行收集器。&lt;br /&gt;
也可以显示进行选择，在java启动参数中增加： -XX:+UseSerialGC 。&lt;/p&gt;

&lt;h3 id=&#34;6-j2se-5-0的hotspot-jvm上的gc学习-8211-parallelgc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;6. J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; ParallelGC&lt;/h3&gt;

&lt;h4 id=&#34;6-1-并行gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;6.1 并行GC&lt;/h4&gt;

&lt;p&gt;现在已经有很多java应用跑在多核的机器上了。&lt;br /&gt;
并行的GC，也称作吞吐量GC，这种GC把多个CPU都用上了，不让CPU再空转。&lt;/p&gt;

&lt;h4 id=&#34;6-2-ygc的并行gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;6.2 YGC的并行GC&lt;/h4&gt;

&lt;p&gt;YGC的情况，还是使用stop-the-world + 复制算法的GC。&lt;br /&gt;
只不过是不再串行，而是充分利用多个CPU，减少GC负荷，增加吞吐量。&lt;br /&gt;
如下图，串行YGC和并行YGC的比较：&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1907&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/0_1302698681Noun.png&#34; alt=&#34;0_1302698681Noun&#34; width=&#34;671&#34; height=&#34;386&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;6-3-年老区的并行gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;6.3 年老区的并行GC&lt;/h4&gt;

&lt;p&gt;也是和串行GC一样，在年老区和永久区使用Mark-Sweep-Compact，利用多核增加了吞吐量和减少GC负荷。&lt;/p&gt;

&lt;h4 id=&#34;6-4-何时使用并行gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;6.4 何时使用并行GC&lt;/h4&gt;

&lt;p&gt;对跑在多核的机器上，并且对暂停时间要求不严格的应用。因为频率较低，但是暂停时间较长的Full GC还是会发生的。&lt;/p&gt;

&lt;h4 id=&#34;6-5-选择并行gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;6.5 选择并行GC&lt;/h4&gt;

&lt;p&gt;在server模式下，并行GC会被自动选择。&lt;br /&gt;
或者可以显式选择并行GC，加启动JVM时加上参数： -XX:UseParallelGC&lt;/p&gt;

&lt;h3 id=&#34;7-j2se-5-0的hotspot-jvm上的gc学习-8211-parallelcompactinggc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;7. J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; ParallelCompactingGC&lt;/h3&gt;

&lt;h4 id=&#34;7-1-parallel-compacting-gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;7.1 Parallel Compacting GC&lt;/h4&gt;

&lt;p&gt;parallelCompactingGC是在J2SE5.0 update6 引入的。&lt;br /&gt;
parallel compacting GC 与 parallel GC的不同地方，是在年老区的收集使用了一个新的算法。并且以后，parallel compacting GC 会取代 parallem GC的。&lt;/p&gt;

&lt;h4 id=&#34;7-2-ygc的并行压缩gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;7.2 YGC的并行压缩GC&lt;/h4&gt;

&lt;p&gt;与并行GC使用的算法一样：stop-the-world 和 复制。&lt;/p&gt;

&lt;h4 id=&#34;7-3-年老区的并行压缩gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;7.3 年老区的并行压缩GC&lt;/h4&gt;

&lt;p&gt;他将把年老区和永久区从逻辑上划分成等大的区域。&lt;br /&gt;
分为三个阶段：&lt;br /&gt;
标记阶段，使用多线程对存在引用的对象进行并行标记。&lt;br /&gt;
分析阶段，GC对各个区域进行分析，GC认为，在经过上次GC后，越左边的区域，有引用的对象密度要远远大于右边的区域。所以就从左往右分析，当某个区域的密度达到一个值的时候，就认为这是一个临界区域，所以这个临界区域左边的区域，将不会进行压缩，而右边的区域，则会进行压缩。&lt;br /&gt;
压缩阶段，多各个需要压缩的区域进行并行压缩。&lt;/p&gt;

&lt;h4 id=&#34;7-4-什么时候使用并行压缩gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;7.4 什么时候使用并行压缩GC&lt;/h4&gt;

&lt;p&gt;同样的，适合在多核的机器上；并且此GC在FGC的时候，暂停时间会更短。&lt;br /&gt;
可以使用参数 -XX:ParallelGCThreads=n 来指定并行的线程数。&lt;/p&gt;

&lt;h4 id=&#34;7-5-开启并行压缩gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;7.5 开启并行压缩GC&lt;/h4&gt;

&lt;p&gt;使用参数 -XX:+UseParallelOldGC&lt;/p&gt;

&lt;h3 id=&#34;8-j2se-5-0的hotspot-jvm上的gc学习-8211-cms-gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;8. J2SE 5.0的HotSpot JVM上的GC学习 &amp;#8211; CMS GC&lt;/h3&gt;

&lt;h4 id=&#34;8-1-concurrent-mark-sweep-gc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;8.1 Concurrent mark sweep GC&lt;/h4&gt;

&lt;p&gt;很多应用对响应时间的要求要大于吞吐量。&lt;br /&gt;
YGC并不暂停多少时间，但FGC对时间的暂用还是很长的。特别是在年老区使用的空间较多时。&lt;br /&gt;
因此， HotSpot引入了一个叫做CMS的收集器，也叫低延时收集器。&lt;/p&gt;

&lt;h4 id=&#34;8-2-cms的ygc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;8.2 CMS的YGC&lt;/h4&gt;

&lt;p&gt;与并行GC同样的方式： stop-the-world 加上 copy。&lt;/p&gt;

&lt;h4 id=&#34;8-3-cms的fgc:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;8.3 CMS的FGC&lt;/h4&gt;

&lt;p&gt;CMS的FGC在大部分是和应用程序一起并发的！&lt;br /&gt;
CMS在FGC的时候，一开始需要做一个短暂的暂停，这个阶段称为最初标记：识别所有被引用的对象。&lt;br /&gt;
在并发标记时候，会和应用程序一起运行。&lt;br /&gt;
因为并发标记是和程序一起运行的，所以在并发标记结束的时候，不能保证所有被引用的对象都被标记，&lt;br /&gt;
为了解决这个问题，GC又进行了一次暂停，这个阶段称为：重标识（remark）。&lt;br /&gt;
在这个过程中，GC会重新对在并发标阶段时候有修改的对象做标记。&lt;br /&gt;
因为remark的暂停要大于最初标记，所以在这时候，需要使用多线程来并行标记。&lt;br /&gt;
在上述动作完成之后，就可以保证所有被引用的对象都被标记了。&lt;br /&gt;
因此，并发清理阶段就可以并发的收集垃圾了。&lt;br /&gt;
下图是serial gc 和 CMS gc 的对比：&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1908&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/0_1302698685pEKJ.png&#34; alt=&#34;0_1302698685pEKJ&#34; width=&#34;678&#34; height=&#34;459&#34; /&gt;&lt;/p&gt;

&lt;p&gt;因为要增加很多额外的动作，比如对被引用的对象重新标记，增加了CMS的工作量，所以他的GC负荷也相应的增加。&lt;br /&gt;
CMS是唯一没有进行压缩的GC。如下图：&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1909&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/0_1302698687O5F5.png&#34; alt=&#34;0_1302698687O5F5&#34; width=&#34;604&#34; height=&#34;247&#34; /&gt;&lt;/p&gt;

&lt;p&gt;没有压缩，对于GC的过程，是节约了时间。但因此产生了内存碎片，所以对于新对象在年老区的分配，就产生了速度上的影响，&lt;br /&gt;
当然，也就包括了对YGC时间的影响了。&lt;br /&gt;
CMS的另一个缺点，就是他需要的堆比较大，因为在并发标记的时候和并发清除的时候，应用程序很有可能在不断产生新的对象，而垃圾又还没有被删除。&lt;br /&gt;
另外，在最初标记之后的并发标记时，原先被引用的对象，有可能变成垃圾。但在这一次的GC中，这是没有被删除的。这种垃圾叫做：漂流垃圾。&lt;br /&gt;
最后，由于没有进行压缩，由此而带来了内存碎片。&lt;br /&gt;
为了解决这个问题，CMS对热点object大小进行了统计，并且估算之后的需求，然后把空闲的内存进行拆分或者合并来满足后续的需求。&lt;br /&gt;
与其他的GC不同，CMS并不在年老区满了之后才开始GC，他需要提前进行GC，用以满足在GC同时需要额外的内存。&lt;br /&gt;
如果在GC的同时，内存不能满足要求了，则GC就变成了并行GC或者串行GC。&lt;br /&gt;
为了防止这种情况，会根据上一次GC的统计来确定启动时间。&lt;br /&gt;
或者是当年老区超过初始容量的话，CMS GC就会启动。&lt;br /&gt;
初始容量的设置可以在JVM启动时增加参数： -XX:CMSInitiatingOccupancyFraction=n&lt;br /&gt;
n是一个百分比，默认值为68。&lt;br /&gt;
总之，CMS比并行GC花费了更少的暂停时间，但是牺牲了吞吐量，以及需要更大的堆区。&lt;/p&gt;

&lt;h4 id=&#34;8-4-额外模式:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;8.4 额外模式&lt;/h4&gt;

&lt;p&gt;为了防止在并发标记的时候，GC线程长期占用CPU，CMS可以把并发标记的时候停下来，把cpu让给应用程序。&lt;br /&gt;
收集器会想并发标记分解成很小的时间串任务，在YGC之间来执行。&lt;br /&gt;
这个功能对于机器的CPU个数少，但又想降低暂停时间的应用来说，非常有用。&lt;/p&gt;

&lt;h4 id=&#34;8-5-何时使用cms:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;8.5 何时使用CMS&lt;/h4&gt;

&lt;p&gt;当CPU资源较空闲，并且需要很低的暂停时间时，可以选择CMS。比如 web servers。&lt;/p&gt;

&lt;h4 id=&#34;8-6-选择cms:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;8.6 选择CMS&lt;/h4&gt;

&lt;p&gt;选择CMS GC： 增加参数 -XX:UseConcMarkSweepGC&lt;br /&gt;
开启额外模式： 增加参数 -XX:+CMSIncreamentalMode&lt;/p&gt;

&lt;h3 id=&#34;9-结合线上启动参数学习:5821ec96f2e556abbdcf79cb49babe8b&#34;&gt;9. 结合线上启动参数学习&lt;/h3&gt;

&lt;p&gt;线上的启动参数&lt;br /&gt;
-Dprogram.name=run.sh -Xmx2g -Xms2g -Xmn256m -XX:PermSize=128m -Xss256k -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -Djava.awt.headless=true -Djava.net.preferIPv4Stack=true -Dcom.sun.management.config.file=/home/admin/web-deploy/conf/jmx/jmx_monitor_management.properties -Djboss.server.home.dir=/home/admin/web-deploy/jboss_server -Djboss.server.home.url=file:/home/admin/web-deploy/jboss_server -Dapplication.codeset=GBK -Ddatabase.codeset=ISO-8859-1 -Ddatabase.logging=false -Djava.endorsed.dirs=/usr/alibaba/jboss/lib/endorsed&lt;/p&gt;

&lt;p&gt;其中：&lt;br /&gt;
-Xmx2g -Xms2g 表示堆为2G&lt;br /&gt;
-Xmn256m 表示新生代为 256m&lt;br /&gt;
-Xss256k 设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右&lt;br /&gt;
-XX:PermSize=128m 表示永久区为128m&lt;br /&gt;
-XX:+DisableExplicitGC 禁用显示的gc，程序程序中使用System.gc()中进行垃圾回收，使用这个参数后系统自动将 System.gc() 调用转换成一个空操作&lt;br /&gt;
-XX:+UseConcMarkSweepGC 表示使用CMS&lt;br /&gt;
-XX:+CMSParallelRemarkEnabled 表示并行remark&lt;br /&gt;
-XX:+UseCMSCompactAtFullCollection 表示在FGC之后进行压缩，因为CMS默认不压缩空间的。&lt;br /&gt;
-XX:+UseCMSInitiatingOccupancyOnly 表示只在到达阀值的时候，才进行CMS GC&lt;br /&gt;
-XX:CMSInitiatingOccupancyFraction=70 设置阀值为70%，默认为68%。&lt;br /&gt;
-XX:+UseCompressedOops JVM优化之压缩普通对象指针（CompressedOops），通常64位JVM消耗的内存会比32位的大1.5倍，这是因为对象指针在64位架构下，长度会翻倍（更宽的寻址）。对于那些将要从32位平台移植到64位的应用来说，平白无辜多了1/2的内存占用，这是开发者不愿意看到的。幸运的是，从JDK 1.6 update14开始，64 bit JVM正式支持了 -XX:+UseCompressedOops 这个可以压缩指针，起到节约内存占用的新参数.&lt;br /&gt;
关于-XX:+UseCMSInitiatingOccupancyOnly 和 -XX:CMSInitiatingOccupancyFraction ，详细解释见下：&lt;br /&gt;
The concurrent collection generally cannot be sped up but it can be started earlier.&lt;br /&gt;
A concurrent collection starts running when the percentage of allocated space in the old generation crosses a threshold. This threshold is calculated based on general experience with the concurrent collector. If full collections are occurring, the concurrent collections may need to be started earlier. The command line flag CMSInitiatingOccupancyFraction can be used to set the level at which the collection is started. Its default value is approximately 68%. The command line to adjust the value is&lt;br /&gt;
-XX:CMSInitiatingOccupancyFraction= The concurrent collector also keeps statistics on the promotion rate into the old generation for the application and makes a prediction on when to start a concurrent collection based on that promotion rate and the available free space in the old generation. Whereas the use of CMSInitiatingOccupancyFraction must be conservative to avoid full collections over the life of the application, the start of a concurrent collection based on the anticipated promotion adapts to the changing requirements of the application. The statistics that are used to calculate the promotion rate are based on the recent concurrent collections. The promotion rate is not calculated until at least one concurrent collection has completed so at least the first concurrent collection has to be initiated because the occupancy has reached CMSInitiatingOccupancyFraction . Setting CMSInitiatingOccupancyFraction to 100 would not cause only the anticipated promotion to be used to start a concurrent collection but would rather cause only non-concurrent collections to occur since a concurrent collection would not start until it was already too late. To eliminate the use of the anticipated promotions to start a concurrent collection set UseCMSInitiatingOccupancyOnly to true.&lt;br /&gt;
-XX:+UseCMSInitiatingOccupancyOnly&lt;br /&gt;
关于内存管理完整详细信息，请查看这份文档：&lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/memorymanagement-whitepaper-150215.pdf&#34;&gt;http://www.oracle.com/technetwork/java/javase/memorymanagement-whitepaper-150215.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;原文：&lt;a href=&#34;http://blog.csdn.net/fenglibing/article/details/6321453&#34;&gt;http://blog.csdn.net/fenglibing/article/details/6321453&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[转]The Go scheduler</title>
      <link>http://:1313/tmp/2015/04/%E8%BD%ACthe-go-scheduler/</link>
      <pubDate>Tue, 14 Apr 2015 03:02:09 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/04/%E8%BD%ACthe-go-scheduler/</guid>
      <description>

&lt;p&gt;One of the big features for Go 1.1 is the new scheduler, contributed by Dmitry Vyukov. The new scheduler has given a dramatic increase in performance for parallel Go programs and with nothing better to do, I figured I&amp;#8217;d write something about it.&lt;/p&gt;

&lt;p&gt;Most of what&amp;#8217;s written in this blog post is already described in the &lt;a href=&#34;https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw&#34; target=&#34;_blank&#34;&gt;original design doc&lt;/a&gt;. It&amp;#8217;s a fairly comprehensive document, but pretty technical.&lt;/p&gt;

&lt;p&gt;All you need to know about the new scheduler is in that design document but this post has pictures, so it&amp;#8217;s clearly superior.&lt;/p&gt;

&lt;h1 id=&#34;TOC_2.:a4b9c3dd7f374cf509714d9eef378dda&#34;&gt;What does the Go runtime need with a scheduler?&lt;/h1&gt;

&lt;p&gt;But before we look at the new scheduler, we need to understand why it&amp;#8217;s needed. Why create a userspace scheduler when the operating system can schedule threads for you?&lt;/p&gt;

&lt;p&gt;The POSIX thread API is very much a logical extension to the existing Unix process model and as such, threads get a lot of the same controls as processes. Threads have their own signal mask, can be assigned CPU affinity, can be put into cgroups and can be queried for which resources they use. All these controls add overhead for features that are simply not needed for how Go programs use goroutines and they quickly add up when you have 100,000 threads in your program.&lt;/p&gt;

&lt;p&gt;Another problem is that the OS can&amp;#8217;t make informed scheduling decisions, based on the Go model. For example, the Go garbage collector requires that all threads are stopped when running a collection and that memory must be in a consistent state. This involves waiting for running threads to reach a point where we know that the memory is consistent.&lt;/p&gt;

&lt;p&gt;When you have many threads scheduled out at random points, chances are that you&amp;#8217;re going to have to wait for a lot of them to reach a consistent state. The Go scheduler can make the decision of only scheduling at points where it knows that memory is consistent. This means that when we stop for garbage collection, we only have to wait for the threads that are being actively run on a CPU core.&lt;/p&gt;

&lt;h1 id=&#34;TOC_3.:a4b9c3dd7f374cf509714d9eef378dda&#34;&gt;Our Cast of Characters&lt;/h1&gt;

&lt;p&gt;There are 3 usual models for threading. One is N:1 where several userspace threads are run on one OS thread. This has the advantage of being very quick to context switch but cannot take advantage of multi-core systems. Another is 1:1 where one thread of execution matches one OS thread. It takes advantage of all of the cores on the machine, but context switching is slow because it has to trap through the OS.&lt;/p&gt;

&lt;p&gt;Go tries to get the best of both worlds by using a M:N scheduler. It schedules an arbitrary number of goroutines onto an arbitrary number of OS threads. You get quick context switches and you take advantage of all the cores in your system. The main disadvantage of this approach is the complexity it adds to the scheduler.&lt;/p&gt;

&lt;p&gt;To acomplish the task of scheduling, the Go Scheduler uses 3 main entities:&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1887&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/our-cast.jpg&#34; alt=&#34;our-cast&#34; width=&#34;391&#34; height=&#34;103&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The triangle represents an OS thread. It&amp;#8217;s the thread of execution managed by the OS and works pretty much like your standard POSIX thread. In the runtime code, it&amp;#8217;s called &lt;strong&gt;M&lt;/strong&gt; for machine.&lt;/p&gt;

&lt;p&gt;The circle represents a goroutine. It includes the stack, the instruction pointer and other information important for scheduling goroutines, like any channel it might be blocked on. In the runtime code, it&amp;#8217;s called a &lt;strong&gt;G&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The rectangle represents a context for scheduling. You can look at it as a localized version of the scheduler which runs Go code on a single thread. It&amp;#8217;s the important part that lets us go from a N:1 scheduler to a M:N scheduler. In the runtime code, it&amp;#8217;s called &lt;strong&gt;P&lt;/strong&gt; for processor. More on this part in a bit.&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1888&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/in-motion.jpg&#34; alt=&#34;in-motion&#34; width=&#34;400&#34; height=&#34;391&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here we see 2 threads (&lt;strong&gt;M&lt;/strong&gt;), each holding a context (&lt;strong&gt;P&lt;/strong&gt;), each running a goroutine (&lt;strong&gt;G&lt;/strong&gt;). In order to run goroutines, a thread must hold a context.&lt;/p&gt;

&lt;p&gt;The number of contexts is set on startup to the value of the GOMAXPROCS environment variable or through the runtime function GOMAXPROCS(). Normally this doesn&amp;#8217;t change during execution of your program. The fact that the number of contexts is fixed means that only GOMAXPROCS are running Go code at any point. We can use that to tune the invocation of the Go process to the individual computer, such at a 4 core PC is running Go code on 4 threads.&lt;/p&gt;

&lt;p&gt;The greyed out goroutines are not running, but ready to be scheduled. They&amp;#8217;re arranged in lists called runqueues. Goroutines are added to the end of a runqueue whenever a goroutine executes a go statement. Once a context has run a goroutine until a scheduling point, it pops a goroutine off its runqueue, sets stack and instruction pointer and begins running the goroutine.&lt;/p&gt;

&lt;p&gt;To bring down mutex contention, each context has its own local runqueue. A previous version of the Go scheduler only had a global runqueue with a mutex protecting it. Threads were often blocked waiting for the mutex to unlocked. This got really bad when you had 32 core machines that you wanted to squeeze as much performance out of as possible.&lt;/p&gt;

&lt;p&gt;The scheduler keeps on scheduling in this steady state as long as all contexts have goroutines to run. However, there are a couple of scenarios that can change that.&lt;/p&gt;

&lt;h1 id=&#34;TOC_4.:a4b9c3dd7f374cf509714d9eef378dda&#34;&gt;Who you gonna (sys)call?&lt;/h1&gt;

&lt;p&gt;You might wonder now, why have contexts at all? Can&amp;#8217;t we just put the runqueues on the threads and get rid of contexts? Not really. The reason we have contexts is so that we can hand them off to other threads if the running thread needs to block for some reason.&lt;/p&gt;

&lt;p&gt;An example of when we need to block, is when we call into a syscall. Since a thread cannot both be executing code and be blocked on a syscall, we need to hand off the context so it can keep scheduling.&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1889&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/syscall.jpg&#34; alt=&#34;syscall&#34; width=&#34;550&#34; height=&#34;400&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here we see a thread giving up its context so that another thread can run it. The scheduler makes sure there are enough threads to run all contexts. &lt;strong&gt;M1&lt;/strong&gt; in the illustration above might be created just for the purpose of handling this syscall or it could come from a thread cache. The syscalling thread will hold on to the goroutine that made the syscall since it&amp;#8217;s technically still executing, albeit blocked in the OS.&lt;/p&gt;

&lt;p&gt;When the syscall returns, the thread must try and get a context in order to run the returning goroutine. The normal mode of operation is to steal a context from one of the other threads. If it can&amp;#8217;t steal one, it will put the goroutine on a global runqueue, put itself on the thread cache and go to sleep.&lt;/p&gt;

&lt;p&gt;The global runqueue is a runqueue that contexts pull from when they run out of their local runqueue. Contexts also periodically check the global runqueue for goroutines. Otherwise the goroutines on global runqueue could end up never running because of starvation.&lt;/p&gt;

&lt;p&gt;This handling of syscalls is why Go programs run with multiple threads, even when GOMAXPROCS is 1. The runtime uses goroutines that call syscalls, leaving threads behind.&lt;/p&gt;

&lt;h1 id=&#34;TOC_5.:a4b9c3dd7f374cf509714d9eef378dda&#34;&gt;Stealing work&lt;/h1&gt;

&lt;p&gt;Another way that the steady state of the system can change is when a context runs out of goroutines to schedule to. This can happen if the amount of work on the contexts&amp;#8217; runqueues is unbalanced. This can cause a context to end up exhausting it&amp;#8217;s runqueue while there is still work to be done in the system. To keep running Go code, a context can take goroutines out of the global runqueue but if there are no goroutines in it, it&amp;#8217;ll have to get them from somewhere else.&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1890&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/04/steal.jpg&#34; alt=&#34;steal&#34; width=&#34;550&#34; height=&#34;400&#34; /&gt;&lt;/p&gt;

&lt;div class=&#34;article&#34;&gt;
  &lt;p&gt;
    That somewhere is the other contexts. When a context runs out, it will try to steal about half of the runqueue from another context. This makes sure there is always work to do on each of the contexts, which in turn makes sure that all threads are working at their maximum capacity.
  &lt;/p&gt;
  
  &lt;h1 id=&#34;TOC_6.&#34;&gt;
    Where to go?
  &lt;/h1&gt;
  
  &lt;p&gt;
    There are many more details to the scheduler, like cgo threads, the LockOSThread() function and integration with the network poller. These are outside the scope of this post, but still merit study. I might write about these later. There are certainly plenty of interesting constructions to be found in the Go runtime library.
  &lt;/p&gt;
  
  &lt;p class=&#34;author&#34;&gt;
    By Daniel Morsing
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;原文：&lt;a href=&#34;http://morsmachine.dk/go-scheduler&#34;&gt;http://morsmachine.dk/go-scheduler&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[转]How to write benchmarks in Go</title>
      <link>http://:1313/tmp/2015/04/%E8%BD%AChow-to-write-benchmarks-in-go/</link>
      <pubDate>Tue, 14 Apr 2015 02:41:24 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/04/%E8%BD%AChow-to-write-benchmarks-in-go/</guid>
      <description>&lt;p&gt;This post continues a series on the testing package I started a few weeks back. You can read the previous article on writing table driven tests here. You can find the code mentioned below in the &lt;a href=&#34;https://github.com/davecheney/fib&#34;&gt;https://github.com/davecheney/fib&lt;/a&gt; repository.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The Go testing package contains a benchmarking facility that can be used to examine the performance of your Go code. This post explains how to use the testing package to write a simple benchmark.&lt;/p&gt;

&lt;p&gt;You should also review the introductory paragraphs of Profiling Go programs, specifically the section on configuring power management on your machine. For better or worse, modern CPUs rely heavily on active thermal management which can add noise to benchmark results.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Writing a benchmark&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We’ll reuse the Fib function from the previous article.&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; Fib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;n &lt;span class=&#34;kw4&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;if&lt;/span&gt; n &lt; &lt;span class=&#34;nu0&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;return&lt;/span&gt; n&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;return&lt;/span&gt; Fib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;n&lt;span class=&#34;sy3&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy3&#34;&gt;+&lt;/span&gt; Fib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;n&lt;span class=&#34;sy3&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Benchmarks are placed inside _test.go files and follow the rules of their Test counterparts. In this first example we’re going to benchmark the speed of computing the 10th number in the Fibonacci series.&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;co1&#34;&gt;// from fib_test.go&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFib10&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;co1&#34;&gt;// run the Fib function b.N times&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; n &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; n &lt; b&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;N&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; n&lt;span class=&#34;sy2&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Fib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Writing a benchmark is very similar to writing a test as they share the infrastructure from the testing package. Some of the key differences are&lt;/p&gt;

&lt;p&gt;Benchmark functions start with Benchmark not Test.&lt;br /&gt;
Benchmark functions are run several times by the testing package. The value of b.N will increase each time until the benchmark runner is satisfied with the stability of the benchmark. This has some important ramifications which we’ll investigate later in this article.&lt;br /&gt;
Each benchmark must execute the code under test b.N times. The for loop in BenchmarkFib10 will be present in every benchmark function.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Running benchmarks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now that we have a benchmark function defined in the tests for the fib package, we can invoke it with go test -bench=.&lt;/p&gt;

&lt;div class=&#34;codecolorer-container bash blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;bash codecolorer&#34;&gt;
          &lt;span class=&#34;sy0&#34;&gt;%&lt;/span&gt; go &lt;span class=&#34;kw3&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;re5&#34;&gt;-bench&lt;/span&gt;=.&lt;br /&gt; PASS&lt;br /&gt; BenchmarkFib10 &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;5000000&lt;/span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;509&lt;/span&gt; ns&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;op&lt;br /&gt; ok &amp;nbsp; &amp;nbsp; &amp;nbsp;github.com&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;davecheney&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;fib &amp;nbsp; &amp;nbsp; &amp;nbsp; 3.084s
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Breaking down the text above, we pass the -bench flag to go test supplying a regular expression matching everything. You must pass a valid regex to -bench, just passing -bench is a syntax error. You can use this property to run a subset of benchmarks.&lt;/p&gt;

&lt;p&gt;The first line of the result, PASS, comes from the testing portion of the test driver, asking go test to run your benchmarks does not disable the tests in the package. If you want to skip the tests, you can do so by passing a regex to the -run flag that will not match anything. I usually use&lt;/p&gt;

&lt;div class=&#34;codecolorer-container bash blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;bash codecolorer&#34;&gt;
          go &lt;span class=&#34;kw3&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;re5&#34;&gt;-run&lt;/span&gt;=XXX &lt;span class=&#34;re5&#34;&gt;-bench&lt;/span&gt;=.
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;The second line is the average run time of the function under test for the final value of b.N iterations. In this case, my laptop can execute Fib(10) in 509 nanoseconds. If there were additional Benchmark functions that matched the -bench filter, they would be listed here.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Benchmarking various inputs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As the original Fib function is the classic recursive implementation, we’d expect it to exhibit exponential behavior as the input grows. We can explore this by rewriting our benchmark slightly using a pattern that is very common in the Go standard library.&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;8&lt;br /&gt;9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; benchmarkFib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;kw4&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; n &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; n &lt; b&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;N&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; n&lt;span class=&#34;sy2&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Fib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu2&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFib1&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &amp;nbsp;&lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt; benchmarkFib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; b&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFib2&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &amp;nbsp;&lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt; benchmarkFib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; b&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFib3&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &amp;nbsp;&lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt; benchmarkFib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; b&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFib10&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt; benchmarkFib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; b&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFib20&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt; benchmarkFib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; b&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFib40&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt; benchmarkFib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;40&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;,&lt;/span&gt; b&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Making benchmarkFib private avoids the testing driver trying to invoke it directly, which would fail as its signature does not match func(*testing.B). Running this new set of benchmarks gives these results on my machine.&lt;/p&gt;

&lt;div class=&#34;codecolorer-container bash blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;bash codecolorer&#34;&gt;
          BenchmarkFib1 &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;1000000000&lt;/span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;2.84&lt;/span&gt; ns&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;op&lt;br /&gt; BenchmarkFib2 &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;500000000&lt;/span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span class=&#34;nu0&#34;&gt;7.92&lt;/span&gt; ns&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;op&lt;br /&gt; BenchmarkFib3 &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;100000000&lt;/span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;13.0&lt;/span&gt; ns&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;op&lt;br /&gt; BenchmarkFib10 &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;5000000&lt;/span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;447&lt;/span&gt; ns&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;op&lt;br /&gt; BenchmarkFib20 &amp;nbsp; &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;50000&lt;/span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;55668&lt;/span&gt; ns&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;op&lt;br /&gt; BenchmarkFib40 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;2&lt;/span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;942888676&lt;/span&gt; ns&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;op
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Apart from confirming the exponential behavior of our simplistic Fib function, there are some other things to observe in this benchmark run.&lt;/p&gt;

&lt;p&gt;Each benchmark is run for a minimum of 1 second by default. If the second has not elapsed when the Benchmark function returns, the value of b.N is increased in the sequence 1, 2, 5, 10, 20, 50, … and the function run again.&lt;br /&gt;
The final BenchmarkFib40 only ran two times with the average was just under a second for each run. As the testing package uses a simple average (total time to run the benchmark function over b.N) this result is statistically weak. You can increase the minimum benchmark time using the -benchtime flag to produce a more accurate result.&lt;/p&gt;

&lt;div class=&#34;codecolorer-container bash blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;bash codecolorer&#34;&gt;
          &lt;span class=&#34;sy0&#34;&gt;%&lt;/span&gt; go &lt;span class=&#34;kw3&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;re5&#34;&gt;-bench&lt;/span&gt;=Fib40 &lt;span class=&#34;re5&#34;&gt;-benchtime&lt;/span&gt;=20s&lt;br /&gt; PASS&lt;br /&gt; BenchmarkFib40 &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;span class=&#34;nu0&#34;&gt;50&lt;/span&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;nu0&#34;&gt;944501481&lt;/span&gt; ns&lt;span class=&#34;sy0&#34;&gt;/&lt;/span&gt;op
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Traps for young players&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Above I mentioned the for loop is crucial to the operation of the benchmark driver. Here are two examples of a faulty Fib benchmark.&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;8&lt;br /&gt;9&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFibWrong&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; n &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; n &lt; b&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;N&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; n&lt;span class=&#34;sy2&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Fib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;n&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFibWrong2&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Fib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;N&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;On my system BenchmarkFibWrong never completes. This is because the run time of the benchmark will increase as b.N grows, never converging on a stable value. BenchmarkFibWrong2 is similarly affected and never completes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A note on compiler optimisations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Before concluding I wanted to highlight that to be completely accurate, any benchmark should be careful to avoid compiler optimisations eliminating the function under test and artificially lowering the run time of the benchmark.&lt;/p&gt;

&lt;div class=&#34;codecolorer-container go blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;8&lt;br /&gt;9&lt;br /&gt;10&lt;br /&gt;11&lt;br /&gt;12&lt;br /&gt;13&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;go codecolorer&#34;&gt;
          &lt;span class=&#34;kw1&#34;&gt;var&lt;/span&gt; result &lt;span class=&#34;kw4&#34;&gt;int&lt;/span&gt;&lt;br /&gt; &lt;br /&gt; &lt;span class=&#34;kw4&#34;&gt;func&lt;/span&gt; BenchmarkFibComplete&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;b &lt;span class=&#34;sy3&#34;&gt;*&lt;/span&gt;testing&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;B&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;var&lt;/span&gt; r &lt;span class=&#34;kw4&#34;&gt;int&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;kw1&#34;&gt;for&lt;/span&gt; n &lt;span class=&#34;sy2&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nu0&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; n &lt; b&lt;span class=&#34;sy3&#34;&gt;.&lt;/span&gt;N&lt;span class=&#34;sy1&#34;&gt;;&lt;/span&gt; n&lt;span class=&#34;sy2&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;sy1&#34;&gt;{&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;co1&#34;&gt;// always record the result of Fib to prevent&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;co1&#34;&gt;// the compiler eliminating the function call.&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; r &lt;span class=&#34;sy2&#34;&gt;=&lt;/span&gt; Fib&lt;span class=&#34;sy1&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nu0&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;sy1&#34;&gt;)&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;co1&#34;&gt;// always store the result to a package level variable&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;span class=&#34;co1&#34;&gt;// so the compiler cannot eliminate the Benchmark itself.&lt;/span&gt;&lt;br /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; result &lt;span class=&#34;sy2&#34;&gt;=&lt;/span&gt; r&lt;br /&gt; &lt;span class=&#34;sy1&#34;&gt;}&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The benchmarking facility in Go works well, and is widely accepted as a reliable standard for measuring the performance of Go code. Writing benchmarks in this manner is an excellent way of communicating a performance improvement, or a regression, in a reproducible way.&lt;/p&gt;

&lt;p&gt;原文：&lt;a href=&#34;http://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go&#34;&gt;http://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>中国姓氏源流示意图</title>
      <link>http://:1313/tmp/2015/03/%E4%B8%AD%E5%9B%BD%E5%A7%93%E6%B0%8F%E6%BA%90%E6%B5%81%E7%A4%BA%E6%84%8F%E5%9B%BE/</link>
      <pubDate>Sat, 28 Mar 2015 02:16:52 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/03/%E4%B8%AD%E5%9B%BD%E5%A7%93%E6%B0%8F%E6%BA%90%E6%B5%81%E7%A4%BA%E6%84%8F%E5%9B%BE/</guid>
      <description>&lt;p&gt;这个很牛逼啊，偶们的也有。&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1877&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2015/03/53f35d25gw1eieoymxma3j20pa0zk7cq.jpg&#34; alt=&#34;53f35d25gw1eieoymxma3j20pa0zk7cq&#34; width=&#34;910&#34; height=&#34;1280&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>通过浏览器更新SVN</title>
      <link>http://:1313/tmp/2015/02/%E9%80%9A%E8%BF%87%E6%B5%8F%E8%A7%88%E5%99%A8%E6%9B%B4%E6%96%B0svn/</link>
      <pubDate>Tue, 03 Feb 2015 07:30:54 +0000</pubDate>
      
      <guid>http://:1313/tmp/2015/02/%E9%80%9A%E8%BF%87%E6%B5%8F%E8%A7%88%E5%99%A8%E6%9B%B4%E6%96%B0svn/</guid>
      <description>&lt;p&gt;简单脚本实现通过浏览器更新SVN。&lt;/p&gt;

&lt;div class=&#34;codecolorer-container php blackboard&#34; style=&#34;overflow:auto;white-space:nowrap;&#34;&gt;
  &lt;table cellspacing=&#34;0&#34; cellpadding=&#34;0&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;line-numbers&#34;&gt;
        &lt;div&gt;
          1&lt;br /&gt;2&lt;br /&gt;3&lt;br /&gt;4&lt;br /&gt;5&lt;br /&gt;6&lt;br /&gt;7&lt;br /&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      
      &lt;td&gt;
        &lt;div class=&#34;php codecolorer&#34;&gt;
          &lt;a href=&#34;http://www.php.net/header&#34;&gt;&lt;span class=&#34;kw3&#34;&gt;header&lt;/span&gt;&lt;/a&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#40;&lt;/span&gt;&lt;span class=&#34;st0&#34;&gt;&#34;Cache-Control:no-cache,must-revalidate&#34;&lt;/span&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#41;&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;;&lt;/span&gt; &amp;nbsp;&lt;br /&gt; &lt;span class=&#34;re0&#34;&gt;$handle&lt;/span&gt; &lt;span class=&#34;sy0&#34;&gt;=&lt;/span&gt; &lt;a href=&#34;http://www.php.net/popen&#34;&gt;&lt;span class=&#34;kw3&#34;&gt;popen&lt;/span&gt;&lt;/a&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#40;&lt;/span&gt;&lt;span class=&#34;st_h&#34;&gt;&#39;export LC_CTYPE=en_US.UTF-8 &amp;&amp; /usr/bin/svn up --username user_test --password pass_test /data1/svn_repo 2&gt;&amp;1&#39;&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;st_h&#34;&gt;&#39;r&#39;&lt;/span&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#41;&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;;&lt;/span&gt; &amp;nbsp;&lt;br /&gt; &lt;span class=&#34;re0&#34;&gt;$read&lt;/span&gt; &lt;span class=&#34;sy0&#34;&gt;=&lt;/span&gt; &lt;a href=&#34;http://www.php.net/stream_get_contents&#34;&gt;&lt;span class=&#34;kw3&#34;&gt;stream_get_contents&lt;/span&gt;&lt;/a&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#40;&lt;/span&gt;&lt;span class=&#34;re0&#34;&gt;$handle&lt;/span&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#41;&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;co1&#34;&gt;//需要 PHP5 或更高版本 &amp;nbsp;&lt;/span&gt;&lt;br /&gt; &lt;span class=&#34;kw1&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st0&#34;&gt;&#34;&lt;pre&gt;&#34;&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;;&lt;/span&gt; &amp;nbsp;&lt;br /&gt; &lt;a href=&#34;http://www.php.net/printf&#34;&gt;&lt;span class=&#34;kw3&#34;&gt;printf&lt;/span&gt;&lt;/a&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#40;&lt;/span&gt;&lt;span class=&#34;re0&#34;&gt;$read&lt;/span&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#41;&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;;&lt;/span&gt; &amp;nbsp;&lt;br /&gt; &lt;span class=&#34;kw1&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;st0&#34;&gt;&#34;&lt;/pre&gt;&#34;&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;;&lt;/span&gt; &amp;nbsp;&lt;br /&gt; &lt;a href=&#34;http://www.php.net/pclose&#34;&gt;&lt;span class=&#34;kw3&#34;&gt;pclose&lt;/span&gt;&lt;/a&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#40;&lt;/span&gt;&lt;span class=&#34;re0&#34;&gt;$handle&lt;/span&gt;&lt;span class=&#34;br0&#34;&gt;&amp;#41;&lt;/span&gt;&lt;span class=&#34;sy0&#34;&gt;;&lt;/span&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;途中踩了两个坑：&lt;/p&gt;

&lt;p&gt;1.svn 有中文文件名&lt;br /&gt;
export LC_CTYPE=en_US.UTF-8 解决此问题&lt;/p&gt;

&lt;p&gt;2.命令返回1，但是没有错误显示&lt;/p&gt;

&lt;p&gt;2&amp;gt;&amp;amp;1 解决此问题&lt;/p&gt;

&lt;p&gt;3.运行此命令要保证运行PHP的服务程序用户具有读写权限&lt;/p&gt;

&lt;p&gt;省事的做法是通过此程序直接checkout一份。&lt;/p&gt;

&lt;p&gt;参考：&lt;a href=&#34;http://zyan.cc/post/371/&#34;&gt;http://zyan.cc/post/371/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Are you too busy to improve?</title>
      <link>http://:1313/tmp/2014/12/are-you-too-busy-to-improve/</link>
      <pubDate>Tue, 23 Dec 2014 02:02:29 +0000</pubDate>
      
      <guid>http://:1313/tmp/2014/12/are-you-too-busy-to-improve/</guid>
      <description>&lt;p&gt;仅自勉。。。&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;aligncenter size-full wp-image-1863&#34; src=&#34;http://blog.webfuns.net/wp-content/uploads/2014/12/Brtku2iCMAI36EV.jpg&#34; alt=&#34;Brtku2iCMAI36EV&#34; width=&#34;600&#34; height=&#34;450&#34; /&gt;&lt;/p&gt;

&lt;p&gt;image from &lt;a class=&#34;account-group js-account-group js-action-profile js-user-profile-link js-nav&#34; href=&#34;https://twitter.com/korkyplunger&#34; data-user-id=&#34;70423999&#34;&gt;&lt;strong class=&#34;fullname js-action-profile-name show-popup-with-id&#34; data-aria-label-part=&#34;&#34;&gt;Christopher Kline&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>